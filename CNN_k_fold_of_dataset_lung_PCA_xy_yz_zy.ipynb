{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "CNN k-fold of dataset_lung_PCA_xy_yz_zy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pawan070bct27/CNN_lung_dataset/blob/main/CNN_k_fold_of_dataset_lung_PCA_xy_yz_zy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwkASYB9Fx1G"
      },
      "source": [
        "# Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ayIPrEuFx1K"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import AveragePooling2D\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, accuracy_score, precision_score, recall_score\n",
        "from collections import deque\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pp9E-9rFx1L"
      },
      "source": [
        "# Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB1qRDn3Fx1L"
      },
      "source": [
        "data_xy = np.load('train_xy.npy')\n",
        "label_xy = np.load('train_label_xy.npy')\n",
        "\n",
        "data_yz = np.load('train_yz.npy')\n",
        "label_yz = np.load('train_label_yz.npy')\n",
        "\n",
        "data_xz = np.load('train_xz.npy')\n",
        "label_xz = np.load('train_label_xz.npy')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1AfhMSTB8KH"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4MHBihJCIuw"
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(data_xy)\n",
        "data_xy_std = sc.transform(data_xy)\n",
        "sc.fit(data_xz)\n",
        "data_xz_std = sc.transform(data_xz)\n",
        "sc.fit(data_yz)\n",
        "data_yz_std = sc.transform(data_yz)\n",
        "#X_test_std = sc.transform(X_test)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdhf_XkQFx1M"
      },
      "source": [
        "#Making a list of dictionaries\n",
        "datasets = [\n",
        "{\n",
        "    'name': 'XY',\n",
        "    'data': data_xy_std,\n",
        "    'label': label_xy\n",
        "},\n",
        "{\n",
        "    'name': 'YZ',\n",
        "    'data': data_yz_std,\n",
        "    'label': label_yz\n",
        "},\n",
        "{\n",
        "    'name': 'XZ',\n",
        "    'data': data_xz_std,\n",
        "    'label': label_xz\n",
        "  \n",
        "}\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "5iONhXy5SQL7",
        "outputId": "eaa54fc6-21cf-4615-b446-deb99dd9e59b"
      },
      "source": [
        "#PCA visualization\n",
        "for i in datasets:\n",
        "  visualize_pca_obj = PCA()\n",
        "  visualize_pca = visualize_pca_obj.fit_transform(i['data'])\n",
        "  plt.bar(range(1, 16), visualize_pca_obj.explained_variance_ratio_[:15], alpha=0.5, align='center')\n",
        "  plt.step(range(1, 16), np.cumsum(visualize_pca_obj.explained_variance_ratio_)[:15], where='mid')\n",
        "  plt.ylabel('Explained variance ratio')\n",
        "  plt.xlabel('Principal component')\n",
        "  plt.title('For data : ' + str(i['name']))\n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAc9UlEQVR4nO3debhcVZnv8e+PcCFMASFpOwMhsTuhO3BlMDKIXgKIl0GIT8sY5uYSHpBRkcbhAmJfG0UbsKVBZIgyCGFoSOgwydS2AmaABBIE05EhIUhEIAQQCLz3j71OdXFSp2rnpHbtU3V+n+ep5+xh7VXvKch5a+219lqKCMzMzADWKjsAMzPrO5wUzMyswknBzMwqnBTMzKzCScHMzCqcFMzMrMJJwawHkkZJCklrlx2LWas4KVjbkfSspLclrah6DSs5pgmSFhdY/36SXpK0adWxiZKWSNpY0te7fR4rJL2ZktqRRcVlncdJwdrVfhGxYdXrxdW5uN2+/UfEdOB+4EIASZsAlwInRMTrEfGdbp/HhqnsAuCW0gK3tuOkYB1D0rqSLpL0YnpdJGnddG6CpMWS/kHSS8DVNa4fIOn7kv4oaRGwb7fzx0h6StIbkhZJOj4d3wC4ExhW3XKRtIOkhyW9JmmppB9JWmcNfsVTgL0l/W+yP/gPRcS0Hj6LfVL5AyLizTV4T+tnnBSsk3wD2AnYFtgG2AH4ZtX5vwQ2BbYAJte4/jjg88B2wHjggG7nX07nBwHHABdK2j790d0beLFby+V94HRgMLAzsAdwYk/BS5onaVJP5yPij8CpwHUpjlN6qGcUcA1wXEQ81VN9ZrU4KVi7ui19A39N0m3p2GHAeRHxckQsA74FHFF1zQfAORHxTkS8XaPOg4CLIuKFiPgT8E/VJyPi3yPivyLzEHAP8JmeAoyI2RHxSESsjIhngR8Du9Yp//GIuL7B7/0IsDFwT/odPyS1jG4GrouIGxvUZbYKJwVrV1+IiE3S6wvp2DDguaoyz6VjXZZFxJ/r1DkMeKHb9RWS9pb0iKQ/SXoN2IesFVCTpLGS7kgdxMuB79Qrn9PlwM+AfSTtXOP8xcB7wFfW8H2sn3JSsE7yItmtoS4j07EujaYEXgps3u16oPIN/Bbg+8BHI2ITYAagOnVfCvwWGBMRg4CvV5VfbZKOTfGdmOq6orqPQtIRwBeBgyLivd6+j/VvTgrWSX4OfFPSEEmDgbOBa1fj+qnAKZJGSPoIcFbVuXWAdYFlwEpJewOfqzr/B2AzSRtXHdsIWA6skPQ3wAmr/RslacjtBWT9BO8AlwGvkPWjIGlr4F+BwyLihR4rMmvAScE6yT8Cs4B5wBPAnHQsr58AdwNz07W3dp2IiDfIOnanAq8Ck4BpVed/S5aUFqV+jmHAGancG6nuuvf4Jc2XdFgPp/8VuCEifpneL8g6xk+TtBXwZWAD4NYazyt8fTU+A+vn5EV2zMysi1sKZmZW4aRgZmYVTgpmZlbhpGBmZhVtNSkYwODBg2PUqFFlh2Fm1lZmz579x4gY0qhc2yWFUaNGMWvWrLLDMDNrK5Kea1zKt4/MzKyKk4KZmVU4KZiZWYWTgpmZVTgpmJlZhZOCmZlVOCmYmVmFk4KZmVW03cNrZmbt4vpHn+f2x5fkKjtu2CDO2W+rgiNqzEnBzCxZnT/ieTz6+z8BsOPoTZtWZ9GcFMzMktsfX8KCpcsZN3RQU+rbcfSmTNx2OJN2HNm4cB/hpGBmbanZ3+qBSkK48fidm1pvO3FHs5m1pa5v9c00buggJm47vKl1thu3FMyscP5W3z7cUjCzwvlbfftwS8HMVtHsb/b+Vt8+3FIws1U0+5u9v9W3D7cUzNqc79dbM7mlYNbmfL/emsktBbMO4G/11ixOCmYtVlQnrlkz+PaRWYu5E9f6MrcUzErg2z3WVzkpmNVR5Mges76o0NtHkvaS9LSkhZLOqnF+pKQHJD0maZ6kfYqMx2x1eWSP9TeFtRQkDQAuAfYEFgMzJU2LiAVVxb4JTI2ISyWNA2YAo4qKyaw3fKvH+pMiWwo7AAsjYlFEvAvcAEzsViaArnb0xsCLBcZjZmYNFNmnMBx4oWp/MbBjtzLnAvdIOhnYAPhsrYokTQYmA4wc2T6LVVjrebin2Zope0jqocCUiBgB7ANcI2mVmCLi8ogYHxHjhwwZ0vIgrX14uKfZmimypbAE2Lxqf0Q6Vu1YYC+AiHhY0kBgMPBygXFZh3MfgFnvFdlSmAmMkTRa0jrAIcC0bmWeB/YAkPS3wEBgWYExmZlZHYW1FCJipaSTgLuBAcBVETFf0nnArIiYBnwF+Imk08k6nY+OiCgqJutb/AyAWd9T6MNrETGDbJhp9bGzq7YXALsUGYP1XV33/5v5R9x9AGZrxk80W6l8/9+sbyl79JGZmfUhTgpmZlbhpGBmZhXuU7BcPFLIrH9wS8Fy8WyhZv2DWwqWm0cKmXU+txTMzKzCScHMzCqcFMzMrMJJwczMKpwUzMyswqOPOpRXIDOz3nBLoUN5BTIz6w23FDqYnysws9XlloKZmVU0TAqSRkj6N0nLJL0s6RZJI1oRnJmZtVaelsLVZGsrDwWGAdPTMTMz6zB5ksKQiLg6Ilam1xRgSMFxmZlZCfIkhVckHS5pQHodDrxSdGBmZtZ6eZLC3wMHAS8BS4EDgGOKDMrMzMrRcEhqRDwH7N+CWMzMrGQ9JgVJZ0bE9yT9CxDdz0fEKYVGZmZmLVevpfBU+jmrFYGYmVn5ekwKETE9bb4VETdVn5N0YKFRmZlZKfJMc/E14KYcx6yXmj15HXgCOzPrnXp9CnsD+wDDJf2w6tQgYGXRgfUnXZPXNfOPuCewM7PeqNdSeJGsP2F/YHbV8TeA04sMqj/y5HVm1hfU61OYC8yVdH1EvNfCmMzMrCR5+hRGSfonYBwwsOtgRHyssKjMzKwUeSfEu5SsH2E34GfAtUUGZWZm5ciTFNaLiPsARcRzEXEusG+xYZmZWRny3D56R9JawO8knQQsATYsNiwzMytDnpbCqcD6wCnAJ4DDgaOKDMrMzMpRt6UgaQBwcEScAazAs6OamXW0ui2FiHgf+HSLYjEzs5Ll6VN4TNI0smkt3uw6GBG3FhaVmZmVIk9SGEi20truVccCcFIwM+sweRbZ6XU/gqS9gIuBAcAVEXF+jTIHAeeSJZq5ETGpt+9nZmZrJk9LoVdSJ/UlwJ7AYmCmpGkRsaCqzBiyGVd3iYhXJf1FUfGYmVljeYak9tYOwMKIWBQR7wI3ABO7lTkOuCQiXgWIiJcLjMfMzBooMikMB16o2l+cjlUbC4yV9CtJj6TbTauQNFnSLEmzli1bVlC4ZmbWMClI+qikKyXdmfbHSTq2Se+/NjAGmAAcCvxE0ibdC0XE5RExPiLGDxkypElvbWZm3eVpKUwB7gaGpf1ngNNyXLcE2Lxqf0Q6Vm0xMC0i3ouI36e6x+So28zMCpAnKQyOiKnABwARsRJ4P8d1M4ExkkZLWgc4BJjWrcxtZK0EJA0mu520KF/oZmbWbHmSwpuSNiMbMoqknYDXG12UksdJZK2Mp4CpETFf0nmS9k/F7gZekbQAeAD4akS80ovfw8zMmiDPkNQvk33D/ytJvwKGAAfkqTwiZgAzuh07u2o7Uv1fzhuwmZkVJ8/Da3Mk7QpsCQh42stzmpl1pjyjj74EbBgR8yPiSWBDSScWH5qZmbVanj6F4yLita6d9KDZccWFZGZmZcmTFAZIUtdOmr5ineJCMjOzsuTpaL4LuFHSj9P+8emYmZl1mDxJ4R/IEsEJaf9e4IrCIjIzs9LkGX30AXBpepmZWQdrmBQk7UK23sEWqbzIHjH4WLGhmZlZq+W5fXQlcDowm3zTW5iZWZvKkxRej4g7C4+kjVz/6PPc/nj3uf16b8HS5YwbOqhp9ZmZ9VaeIakPSLpA0s6Stu96FR5ZH3b740tYsHR50+obN3QQE7ftvtSEmVnr5Wkp7Jh+jq86FsDuzQ+nfYwbOogbj9+57DDMzJoqz+ij3VoRiJmZlS9PSwFJ+wJbAQO7jkXEeUUFZWZm5cgzId5lwMHAyWTDUQ8kG55qZmYdJk9H86ci4kjg1Yj4FrAz2QppZmbWYfIkhbfTz7ckDQPeA4YWF5KZmZUlT5/CHZI2AS4A5pCNPPLcR2ZmHSjP6KNvp81bJN0BDIyIhms0m5lZ++kxKUjaPSLul/R3Nc4REbcWG5qZmbVavZbCrsD9wH41zgXgpGBm1mF6TAoRcY6ktYA7I2JqC2MyM7OS1B19lNZSOLNFsZiZWcnyDEn9haQzJG0uadOuV+GRmZlZy+UZknpw+vmlqmMBeJEdM7MOk2dI6uhWBGJmZuXLOyHe1sA4Pjwh3s+KCsrMzMqRZ43mc4AJZElhBrA38J+Ak4KZWYfJ09F8ALAH8FJEHANsA2xcaFRmZlaKXBPipaGpKyUNAl4GNi82LDMzK0OePoVZaUK8nwCzgRXAw4VGZWZmpcgz+ujEtHmZpLuAQRExr9iwzMysDHlWXpsmaZKkDSLiWScEM7POladP4QfAp4EFkm6WdICkgY0uMjOz9pPn9tFDwEOSBgC7A8cBVwGDCo7NzMxaLO/Da+uRTaF9MLA98NMigzIzs3LkeXhtKrADcBfwI+ChNETVzMw6TJ6WwpXAoRHxftHBmJlZuRp2NEfE3b1NCJL2kvS0pIWSzqpT7ouSQtL43ryPmZk1R57RR72SOqYvIZsraRxwqKRxNcptBJwKPFpULGZmlk9hSYGsH2JhRCyKiHeBG4CJNcp9G/gu8OcCYzEzsxx67FOQtH29CyNiToO6hwMvVO0vBnas8R6bR8S/S/pqnVgmA5MBRo4c2eBtzcyst+p1NP8g/RwIjAfmAgI+DswCdl6TN5a0FvDPwNGNykbE5cDlAOPHj481eV8zM+tZj7ePImK3iNgNWApsHxHjI+ITwHbAkhx1L+HDs6mO6HbdRsDWwIOSngV2Aqa5s9nMrDx5hqRuGRFPdO1ExJOS/jbHdTOBMZJGkyWDQ4BJVfW8Dgzu2pf0IHBGRMzKGXvTfWv6fBa8uLxhuQVLlzNuqB/oNrPOkycpzJN0BXBt2j8MaDgpXkSslHQScDcwALgqIuZLOg+YFRHTeht0b1147zN1zz/2/Gsse+OdumVGfGQ9xg0dxMRthzczNDOzPiFPUjgGOIFs2CjAfwCX5qk8ImaQLeFZfezsHspOyFNnkXYdO6RhmdP3HNuCSMzMypFnQrw/S7oMmBERT7cgJjMzK0me9RT2Bx4nm/sISdtKavmtHzMzK16eh9fOIXsQ7TWAiHgcGF1kUGZmVo48SeG9NFKomp8VMDPrQHk6mudLmgQMkDQGOAX4dbFhmZlZGfK0FE4GtgLeAX4OLAdOKzIoMzMrR57RR28B30gvMzPrYHlWXhsLnAGMqi4fEbsXF5aZmZUhT5/CTcBlwBWAV18zM+tgeZLCyojI9QSzmZm1tzwdzdMlnShpqKRNu16FR2ZmZi2Xp6VwVPpZvQhOAB9rfjhmZlamPKOP/PSymVk/UW85zt0j4n5Jf1frfETcWlxYZmZWhnothV2B+4H9apwLwEnBzKzD9JgUIuKc9POY1oVjZmZlytPRjKR9yaa6GNh1LCLOKyooMzMrR571FC4DDiabA0nAgcAWBcdlZmYlyPOcwqci4kjg1Yj4FrAz4DUpzcw6UJ6k8Hb6+ZakYcB7wNDiQjIzs7Lk6VO4Q9ImwAXAHLKRR1cUGpWZmZUiz8Nr306bt0i6AxhYYyU2MzPrAPUeXqv50Fo654fXzMw6UL2WQq2H1rr44TUzsw5U7+E1P7RmZtbP5HlOYTNJP5Q0R9JsSRdL2qwVwZmZWWvlGZJ6A7AM+CJwQNq+scigzMysHHmGpA6tGoEE8I+SDi4qIDMzK0+elsI9kg6RtFZ6HQTcXXRgZmbWenmSwnHA9cA76XUDcLykNyQtLzI4MzNrrTwPr23UikDMzKx8eUYfHdttf4Ckc4oLyczMypLn9tEekmZIGippa+ARwK0HM7MOlOf20aQ02ugJ4E1gUkT8qvDIzMys5fLcPhoDnArcAjwHHCFp/aIDMzOz1stz+2g68H8j4nhgV+B3wMxCozIzs1LkeXhth4hYDhARAfxA0vRiwzIzszL02FKQdCZARCyXdGC300cXGZSZmZWj3u2jQ6q2v9bt3F55Kpe0l6SnJS2UdFaN81+WtEDSPEn3SdoiT71mZlaMeklBPWzX2l/1YmkAcAmwNzAOOFTSuG7FHgPGR8THgZuB7zWM2MzMClMvKUQP27X2a9kBWBgRiyLiXbLpMSZ+qJKIByLirbT7CDAiR71mZlaQeh3N26S5jQSsVzXPkYCBOeoeDrxQtb8Y2LFO+WOBO3PUa2ZmBam38tqAVgUh6XBgPNmQ11rnJwOTAUaOHNmqsMzM+p08zyn01hJg86r9EenYh0j6LPANYP+IeKdWRRFxeUSMj4jxQ4YMKSRYMzMrNinMBMZIGi1pHbLRTNOqC0jaDvgxWUJ4ucBYzMwsh8KSQkSsBE4iW5DnKWBqRMyXdJ6k/VOxC4ANgZskPS5pWg/VmZlZC+R5ornXImIGMKPbsbOrtj9b5PubmdnqKfL2kZmZtRknBTMzq3BSMDOzCicFMzOrcFIwM7MKJwUzM6sodEhqf3Dhvc+s0fWn7zm2SZGYma05txTMzKzCScHMzCqcFMzMrMJJwczMKtzR3Mesacc1uPPazHrPLQUzM6twUjAzswonBTMzq3BSMDOzCicFMzOrcFIwM7MKJwUzM6twUjAzswonBTMzq3BSMDOzCicFMzOrcFIwM7MKJwUzM6twUjAzswonBTMzq3BSMDOzCicFMzOr8Mpr/cCarubmldzM+g+3FMzMrMJJwczMKpwUzMyswknBzMwq3NFsveLOa7PO5JaCmZlVuKVgfcKatjzArQ+zZnBLwczMKtxSsI7V7H4Pt2asPyg0KUjaC7gYGABcERHndzu/LvAz4BPAK8DBEfFskTGZ9SXtkLg8qKB/KSwpSBoAXALsCSwGZkqaFhELqoodC7waEX8t6RDgu8DBRcVkZn1Df0yG7dLSLLJPYQdgYUQsioh3gRuAid3KTAR+mrZvBvaQpAJjMjOzOhQRxVQsHQDsFRH/J+0fAewYESdVlXkylVmc9v8rlfljt7omA5PT7pbA02l7MPChsn2QY2wOx9g87RCnY2yO6hi3iIghjS5oi47miLgcuLz7cUmzImJ8CSHl5hibwzE2TzvE6RibozcxFnn7aAmwedX+iHSsZhlJawMbk3U4m5lZCYpMCjOBMZJGS1oHOASY1q3MNOCotH0AcH8UdT/LzMwaKuz2UUSslHQScDfZkNSrImK+pPOAWRExDbgSuEbSQuBPZIljdaxyS6kPcozN4Ribpx3idIzNsdoxFtbRbGZm7cfTXJiZWYWTgpmZVbRlUpC0l6SnJS2UdFbZ8dQiaXNJD0haIGm+pFPLjqknkgZIekzSHWXHUoukTSTdLOm3kp6StHPZMXUn6fT03/lJST+XNLAPxHSVpJfT80BdxzaVdK+k36WfH+mDMV6Q/lvPk/RvkjYpM8YU0ypxVp37iqSQNLiM2KriqBmjpJPT5zlf0vca1dN2SaFq+oy9gXHAoZLGlRtVTSuBr0TEOGAn4Et9NE6AU4Gnyg6ijouBuyLib4Bt6GOxShoOnAKMj4ityQZWrO6giSJMAfbqduws4L6IGAPcl/bLNIVVY7wX2DoiPg48A3yt1UHVMIVV40TS5sDngOdbHVANU+gWo6TdyGaO2CYitgK+36iStksK5Js+o3QRsTQi5qTtN8j+kA0vN6pVSRoB7AtcUXYstUjaGPhfZCPViIh3I+K1cqOqaW1gvfS8zfrAiyXHQ0T8B9movmrVU8v8FPhCS4PqplaMEXFPRKxMu4+QPeNUqh4+S4ALgTOB0kfs9BDjCcD5EfFOKvNyo3raMSkMB16o2l9MH/xjW03SKGA74NFyI6npIrL/qT8oO5AejAaWAVenW1xXSNqg7KCqRcQSsm9gzwNLgdcj4p5yo+rRRyNiadp+CfhomcHk8PfAnWUHUYukicCSiJhbdix1jAU+I+lRSQ9J+mSjC9oxKbQVSRsCtwCnRcTysuOpJunzwMsRMbvsWOpYG9geuDQitgPepPxbHh+S7stPJEtgw4ANJB1eblSNpQdFS/+G2xNJ3yC7DXtd2bF0J2l94OvA2WXH0sDawKZkt7C/CkxtNOloOyaFPNNn9AmS/gdZQrguIm4tO54adgH2l/Qs2W243SVdW25Iq1gMLI6IrlbWzWRJoi/5LPD7iFgWEe8BtwKfKjmmnvxB0lCA9LPh7YQySDoa+DxwWB+d5eCvyL4EzE3/fkYAcyT9ZalRrWoxcGtkfkN2R6Buh3g7JoU802eULmXjK4GnIuKfy46nloj4WkSMiIhRZJ/j/RHRp77hRsRLwAuStkyH9gAW1LmkDM8DO0laP/1334M+1hlepXpqmaOA20uMpaa0ONeZwP4R8VbZ8dQSEU9ExF9ExKj072cxsH36/7UvuQ3YDUDSWGAdGszs2nZJIXVAdU2f8RQwNSLmlxtVTbsAR5B9+348vfYpO6g2dTJwnaR5wLbAd0qO50NSK+ZmYA7wBNm/q9KnQJD0c+BhYEtJiyUdC5wP7Cnpd2QtnPPr1VFSjD8CNgLuTf9uLiszRugxzj6lhxivAj6WhqneABzVqOXlaS7MzKyi7VoKZmZWHCcFMzOrcFIwM7MKJwUzM6twUjAzswonBSudpPfT0MMnJd2UnhatVe7Xvax/vKQfrkF8K3p7bTuRdFpPn731Hx6SaqWTtCIiNkzb1wGzqx/4k7R21QRppcbXydKTueMjou7DTdbZ3FKwvuaXwF9LmiDpl5KmkZ5g7vrGns49WLXGwnVd87lI+qSkX0uaK+k3kjZK5e9I58+VdI2kh9OaAsel4xtKuk/SHElPpMnO6pJ0ZJrzf66ka9KxUZLuT8fvkzQyHZ8i6VJJj0halGK6Stn6EFOq6lwh6UJlc9/fJ2lIOr5turZrjYGPpOMPSvpu+l2fkfSZdHyAsnUJZqZrjq/32Uk6hWzepgckPdCE/47WriLCL79KfQEr0s+1yaZdOAGYQDb53ega5SYAr5PNN7MW2VOcnyZ7hH8R8MlUblCqcwJwRzp2LjAXWI9sDpgXyP4Yrg0MSmUGAwv575b0ihoxb0U21//gtL9p+jmd7KlRyGb4vC1tTyF7olRkk+ctB/5nin82sG0qF2Tz/UA22dqP0vY8YNe0fR5wUdp+EPhB2t4H+EXangx8M22vC8wim6un5meXyj3b9fv41X9fbilYX7CepMfJ/nA9T1o7AfhNRPy+h2t+ExGLI+ID4HFgFLAlsDQiZgJExPKofdvp9oh4O7LbJA+QrdEh4DtpKo1fkE3HXm9a6d2Bm1IdRETXPPY7A9en7WvIklWX6RERZFNh/CGy+XM+AOan+CGbsOzGtH0t8Glla0psEhEPpeM/JVtjokvXZIuzq+r5HHBk+lwfBTYDxqRztT47MyD7dmRWtrcjYtvqA+lu0Jt1rnmnavt9Vu//5e4daQEcBgwBPhER76X7681eUrMr5g/4cPwf0HP8eTr9uuqq/hwEnBwRd1cXlDSBNfvsrMO5pWCd5GlgqNJCIqk/odYfvImSBkrajOx2ykxgY7K1Jd5TtoThFg3e637gwFQHkjZNx3/Nfy/FeRhZH8nqWAs4IG1PAv4zIl4HXu3qLyCbaPGhWhdXuRs4Qdn07Ugaq8aLE71BNhGd9WP+hmAdIyLelXQw8C+S1gPeJpsJtLt5ZLeNBgPfjogX06in6ZKeILuN9dsG7zVf0v8DHpL0PvAYcDTZjK5XS/oq2Ypxx6zmr/EmsIOkb5KtdXBwOn4UcFkaMrooR71XkN0WmpM64ZfReOnNy4G7JL0YEbutZtzWITwk1foVSeeSdRw3XMC8DP1l+Kv1Xb59ZGZmFW4pmJlZhVsKZmZW4aRgZmYVTgpmZlbhpGBmZhVOCmZmVvH/AYAitGm3c8mcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvUa0i25FnIk",
        "outputId": "ccf7b61c-e8aa-47bf-bf31-6ed9e0f68ca6"
      },
      "source": [
        "visualize_pca.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1002, 1002)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTzAkYlXFx1N"
      },
      "source": [
        "#defining a function for splitting datasets after application of PCA on them\n",
        "def split_datasets():\n",
        "  pca = PCA()\n",
        "  pca_obj = pca.fit_transform(m['data'])\n",
        "  pca_obj = pca_obj[:,:6]\n",
        "  pca_obj = pca_obj.reshape(167,6,6)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(pca_obj, m['label'].reshape(167,6,1), test_size=0.3, random_state=101, shuffle = True)\n",
        "\n",
        "  X_train = X_train.reshape(X_train.shape[0]*6, 6)\n",
        "  y_train = y_train.reshape(y_train.shape[0]*6,)\n",
        "\n",
        "  X_test = X_test.reshape(X_test.shape[0]*6, 6)\n",
        "  y_test = y_test.reshape(y_test.shape[0]*6,)\n",
        "  \n",
        "    \n",
        "  X_train = X_train.reshape(696, 6, 1,1)\n",
        "  X_test = X_test.reshape(306, 6, 1,1)  \n",
        "\n",
        "  y_train = np_utils.to_categorical(y_train, 2)\n",
        "  y_test = np_utils.to_categorical(y_test, 2) \n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pupae2LvTOF"
      },
      "source": [
        "#Designing a model\n",
        "def makemodel():\n",
        "  model = Build_model()\n",
        "  return model\n",
        "\n",
        "def Build_model():\n",
        "  import tensorflow as tf\n",
        "  #from tensorflow.keras.callbacks import TensorBoard\n",
        "  #import time\n",
        "  #NAME = \"Lung_cancer_typical_CNN{}\".format(int(time.time()))\n",
        "  #tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
        "  # Convolutional \n",
        "  cnn = Sequential()\n",
        "  input_shape = (6, 1, 1) \n",
        "\n",
        "  # conv1 layer\n",
        "  cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), activation ='relu', input_shape = input_shape, padding='same'))\n",
        "  cnn.add(tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2, padding='same'))\n",
        "  cnn.add((tf.keras.layers.Dropout(0.2)))\n",
        "\n",
        "  # conv2 layer\n",
        "  cnn.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), activation ='relu', input_shape = input_shape, padding='same'))\n",
        "  cnn.add(tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2, padding='same'))\n",
        "  cnn.add((tf.keras.layers.Dropout(0.2)))\n",
        "\n",
        "  cnn.add(tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation ='relu', input_shape = input_shape, padding='same'))\n",
        "  cnn.add(tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2, padding='same'))\n",
        "  cnn.add((tf.keras.layers.Dropout(0.2)))\n",
        "\n",
        "  # conv3 layer\n",
        "  cnn.add(tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation ='relu', input_shape = input_shape, padding='same'))\n",
        "  cnn.add(tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2, padding='same'))\n",
        "  cnn.add((tf.keras.layers.Dropout(0.2)))\n",
        "  cnn.add(tf.keras.layers.Flatten())\n",
        "  # fc1 layer\n",
        "  cnn.add(tf.keras.layers.Dense(512, activation= 'relu'))\n",
        "  cnn.add((tf.keras.layers.Dropout(0.2)))\n",
        "  # fc2 layer\n",
        "  cnn.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "  return cnn"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MLzf_81DOQWe",
        "outputId": "18af4878-a8eb-4be2-f34c-6fac8dd54ccd"
      },
      "source": [
        "\n",
        "# Below for loop iterates through your dataset list\n",
        "#window = deque([],maxlen=2)\n",
        "speci = deque([])\n",
        "sensi = deque([])\n",
        "au    = deque([])\n",
        "_f1score = deque([])\n",
        "_accuracy = deque([])\n",
        "\n",
        "# NAME = \"Lung_cancer_typical_CNN{}\".format(int(time.time()))\n",
        "# tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
        "\n",
        "\n",
        "for m in datasets:\n",
        "# Define per-fold score containers\n",
        "    acc_per_fold = []\n",
        "    loss_per_fold = []\n",
        "    X_train, X_test, y_train, y_test = split_datasets()\n",
        "    print(X_train.shape)\n",
        "    print(y_train.shape)\n",
        "    # Merge inputs and targets\n",
        "    inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "    targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "    # Define the K-fold Cross Validator\n",
        "    from sklearn.model_selection import KFold\n",
        "    kfold = KFold(n_splits= 5, shuffle=True)\n",
        "\n",
        "    # K-fold Cross Validation model evaluation\n",
        "    fold_no = 1\n",
        "    for train, test in kfold.split(inputs, targets):\n",
        "      \n",
        "      # Generate a print\n",
        "      print('------------------------------------------------------------------------')\n",
        "      print(f'Training for fold {fold_no} ...')\n",
        "      model = makemodel()\n",
        "      model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "      model.summary()\n",
        "      # Fit data to model\n",
        "      history1 = model.fit(inputs[train], targets[train], validation_data=(inputs[test], targets[test]), batch_size=4, epochs=50, verbose=1, shuffle=True)\n",
        "         \n",
        "      tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)\n",
        "\n",
        "      # Generate generalization metrics\n",
        "      scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "      print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "      acc_per_fold.append(scores[1] * 100)\n",
        "      loss_per_fold.append(scores[0])\n",
        "      # Increase fold numberÃ¥\n",
        "      fold_no = fold_no + 1\n",
        "    # == Provide average scores ==\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Score per fold')\n",
        "    for i in range(0, len(acc_per_fold)):\n",
        "      print('------------------------------------------------------------------------')\n",
        "      print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Average scores for all folds:')\n",
        "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "    print('------------------------------------------------------------------------')\n",
        "    \n",
        "    converted_ytest = y_test.argmax(axis=1)\n",
        "    y_pred=model.predict(X_test)\n",
        "    # from sklearn.metrics import confusion_matrix\n",
        "    # cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "    # window.append(cm)\n",
        "# Compute False postive rate, and True positive rate\n",
        "    fpr, tpr, thresholds = roc_curve(converted_ytest, model.predict_proba(X_test)[:,1])\n",
        " #Compute precision   \n",
        "    raw_speci= precision_score(converted_ytest, y_pred.argmax(axis=1))\n",
        "    speci.append(((raw_speci)))\n",
        "#Compute recall\n",
        "    raw_sensi= precision_score(converted_ytest, y_pred.argmax(axis=1))\n",
        "    sensi.append(((raw_sensi)))\n",
        "    # sensi.append(\"{:.0%}\".format(tpr))\n",
        "# Calculate Area under the curve to display on the plot\n",
        "    auc = roc_auc_score(converted_ytest, y_pred.argmax(axis = 1))\n",
        "    au.append(((auc)))\n",
        "#accuracy\n",
        "    _acc = accuracy_score(converted_ytest, y_pred.argmax(axis=1))\n",
        "    _accuracy.append((_acc))\n",
        "# F1 -score\n",
        "    _fscore1 = f1_score(converted_ytest, y_pred.argmax(axis=1))\n",
        "    _f1score.append(((_fscore1)))\n",
        "\n",
        "# Now, plot the computed values\n",
        "    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (m['name'], auc))\n",
        "# Custom settings for the plot \n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Specificity(False Positive Rate)')\n",
        "plt.ylabel('Sensitivity(True Positive Rate)')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show() \n",
        "  # Display\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(696, 6, 1, 1)\n",
            "(696, 2)\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.6658 - accuracy: 0.6172 - val_loss: 0.5766 - val_accuracy: 0.7214\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.6314 - accuracy: 0.6890 - val_loss: 0.5935 - val_accuracy: 0.7164\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5755 - accuracy: 0.7417 - val_loss: 0.6187 - val_accuracy: 0.6219\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5931 - accuracy: 0.7286 - val_loss: 0.5079 - val_accuracy: 0.7463\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5168 - accuracy: 0.7503 - val_loss: 0.4981 - val_accuracy: 0.7761\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5241 - accuracy: 0.7524 - val_loss: 0.4918 - val_accuracy: 0.7711\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5238 - accuracy: 0.7664 - val_loss: 0.4736 - val_accuracy: 0.7512\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4844 - accuracy: 0.7525 - val_loss: 0.4705 - val_accuracy: 0.7960\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4984 - accuracy: 0.7669 - val_loss: 0.5079 - val_accuracy: 0.7761\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5041 - accuracy: 0.7437 - val_loss: 0.5795 - val_accuracy: 0.7164\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5060 - accuracy: 0.7757 - val_loss: 0.4370 - val_accuracy: 0.7861\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4431 - accuracy: 0.7970 - val_loss: 0.4928 - val_accuracy: 0.7861\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4616 - accuracy: 0.7719 - val_loss: 0.5032 - val_accuracy: 0.7811\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4053 - accuracy: 0.7838 - val_loss: 0.5041 - val_accuracy: 0.7463\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4347 - accuracy: 0.8110 - val_loss: 0.5137 - val_accuracy: 0.7413\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4360 - accuracy: 0.7912 - val_loss: 0.4750 - val_accuracy: 0.7811\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4002 - accuracy: 0.8205 - val_loss: 0.4695 - val_accuracy: 0.7761\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.7987 - val_loss: 0.4294 - val_accuracy: 0.8010\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4578 - accuracy: 0.8034 - val_loss: 0.4721 - val_accuracy: 0.8010\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3954 - accuracy: 0.8081 - val_loss: 0.4277 - val_accuracy: 0.8060\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4060 - accuracy: 0.8186 - val_loss: 0.4182 - val_accuracy: 0.8010\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4029 - accuracy: 0.8256 - val_loss: 0.4429 - val_accuracy: 0.7761\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3650 - accuracy: 0.8191 - val_loss: 0.3910 - val_accuracy: 0.8060\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3791 - accuracy: 0.8361 - val_loss: 0.4240 - val_accuracy: 0.8159\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3830 - accuracy: 0.8310 - val_loss: 0.4535 - val_accuracy: 0.8060\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4142 - accuracy: 0.8042 - val_loss: 0.4053 - val_accuracy: 0.8259\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3611 - accuracy: 0.8384 - val_loss: 0.3919 - val_accuracy: 0.8109\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3996 - accuracy: 0.8199 - val_loss: 0.4209 - val_accuracy: 0.8010\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3983 - accuracy: 0.8219 - val_loss: 0.5124 - val_accuracy: 0.7960\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3417 - accuracy: 0.8482 - val_loss: 0.4600 - val_accuracy: 0.7861\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3859 - accuracy: 0.8452 - val_loss: 0.4005 - val_accuracy: 0.8557\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3219 - accuracy: 0.8513 - val_loss: 0.4066 - val_accuracy: 0.8209\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3355 - accuracy: 0.8532 - val_loss: 0.3579 - val_accuracy: 0.8408\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3098 - accuracy: 0.8867 - val_loss: 0.3525 - val_accuracy: 0.8607\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3511 - accuracy: 0.8335 - val_loss: 0.4169 - val_accuracy: 0.8408\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3475 - accuracy: 0.8577 - val_loss: 0.3625 - val_accuracy: 0.8060\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3770 - accuracy: 0.8392 - val_loss: 0.3645 - val_accuracy: 0.8458\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3593 - accuracy: 0.8116 - val_loss: 0.3457 - val_accuracy: 0.8756\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3362 - accuracy: 0.8490 - val_loss: 0.3310 - val_accuracy: 0.8657\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2713 - accuracy: 0.8808 - val_loss: 0.3580 - val_accuracy: 0.8458\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3203 - accuracy: 0.8644 - val_loss: 0.3590 - val_accuracy: 0.8607\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3359 - accuracy: 0.8481 - val_loss: 0.2937 - val_accuracy: 0.8706\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3316 - accuracy: 0.8463 - val_loss: 0.3516 - val_accuracy: 0.8557\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3265 - accuracy: 0.8687 - val_loss: 0.3838 - val_accuracy: 0.8657\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3260 - accuracy: 0.8642 - val_loss: 0.2940 - val_accuracy: 0.8756\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2901 - accuracy: 0.8839 - val_loss: 0.3592 - val_accuracy: 0.8408\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3216 - accuracy: 0.8509 - val_loss: 0.3274 - val_accuracy: 0.8806\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2979 - accuracy: 0.8785 - val_loss: 0.3726 - val_accuracy: 0.8657\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3033 - accuracy: 0.8625 - val_loss: 0.3759 - val_accuracy: 0.8756\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2691 - accuracy: 0.9037 - val_loss: 0.4248 - val_accuracy: 0.8308\n",
            "Score for fold 1: loss of 0.42478278279304504; accuracy of 83.08457732200623%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6795 - accuracy: 0.6033 - val_loss: 0.6397 - val_accuracy: 0.6418\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.6129 - accuracy: 0.6975 - val_loss: 0.6701 - val_accuracy: 0.6517\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5974 - accuracy: 0.7287 - val_loss: 0.6954 - val_accuracy: 0.6567\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5777 - accuracy: 0.6761 - val_loss: 0.5539 - val_accuracy: 0.7065\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5713 - accuracy: 0.7124 - val_loss: 0.5145 - val_accuracy: 0.7065\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5103 - accuracy: 0.7369 - val_loss: 0.4772 - val_accuracy: 0.7463\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4887 - accuracy: 0.7432 - val_loss: 0.4811 - val_accuracy: 0.7612\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5360 - accuracy: 0.7083 - val_loss: 0.4708 - val_accuracy: 0.7910\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5016 - accuracy: 0.7557 - val_loss: 0.4357 - val_accuracy: 0.7811\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4733 - accuracy: 0.7844 - val_loss: 0.4592 - val_accuracy: 0.7861\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.8074 - val_loss: 0.4309 - val_accuracy: 0.7711\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.8091 - val_loss: 0.4405 - val_accuracy: 0.7910\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4888 - accuracy: 0.7527 - val_loss: 0.4913 - val_accuracy: 0.7612\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4541 - accuracy: 0.7593 - val_loss: 0.6939 - val_accuracy: 0.7761\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5006 - accuracy: 0.7974 - val_loss: 0.4708 - val_accuracy: 0.7711\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4141 - accuracy: 0.8072 - val_loss: 0.6939 - val_accuracy: 0.6866\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4633 - accuracy: 0.7970 - val_loss: 0.4494 - val_accuracy: 0.7761\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4074 - accuracy: 0.8002 - val_loss: 0.4327 - val_accuracy: 0.7761\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4045 - accuracy: 0.8081 - val_loss: 0.4106 - val_accuracy: 0.7960\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4470 - accuracy: 0.7896 - val_loss: 0.4163 - val_accuracy: 0.8010\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4086 - accuracy: 0.7837 - val_loss: 0.4214 - val_accuracy: 0.7861\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4066 - accuracy: 0.8075 - val_loss: 0.4447 - val_accuracy: 0.7612\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3654 - accuracy: 0.8209 - val_loss: 0.4006 - val_accuracy: 0.8109\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4172 - accuracy: 0.8226 - val_loss: 0.3981 - val_accuracy: 0.8060\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3925 - accuracy: 0.8591 - val_loss: 0.3791 - val_accuracy: 0.8159\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3780 - accuracy: 0.8250 - val_loss: 0.4061 - val_accuracy: 0.8010\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4124 - accuracy: 0.8011 - val_loss: 0.4980 - val_accuracy: 0.7711\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3803 - accuracy: 0.8286 - val_loss: 0.4030 - val_accuracy: 0.8259\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3614 - accuracy: 0.8434 - val_loss: 0.4174 - val_accuracy: 0.8259\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4000 - accuracy: 0.8222 - val_loss: 0.3800 - val_accuracy: 0.8259\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3518 - accuracy: 0.8519 - val_loss: 0.4218 - val_accuracy: 0.8209\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3741 - accuracy: 0.8368 - val_loss: 0.3517 - val_accuracy: 0.8259\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3597 - accuracy: 0.8449 - val_loss: 0.4335 - val_accuracy: 0.7910\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3639 - accuracy: 0.8184 - val_loss: 0.4725 - val_accuracy: 0.8010\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3890 - accuracy: 0.8236 - val_loss: 0.4553 - val_accuracy: 0.7960\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3939 - accuracy: 0.8306 - val_loss: 0.4195 - val_accuracy: 0.8259\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3627 - accuracy: 0.8482 - val_loss: 0.3935 - val_accuracy: 0.8159\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3285 - accuracy: 0.8606 - val_loss: 0.3673 - val_accuracy: 0.8408\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3048 - accuracy: 0.8624 - val_loss: 0.4123 - val_accuracy: 0.8109\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3956 - accuracy: 0.8289 - val_loss: 0.3605 - val_accuracy: 0.7960\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3615 - accuracy: 0.8573 - val_loss: 0.4585 - val_accuracy: 0.8507\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3485 - accuracy: 0.8625 - val_loss: 0.3450 - val_accuracy: 0.8657\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3011 - accuracy: 0.8792 - val_loss: 0.3610 - val_accuracy: 0.8458\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2890 - accuracy: 0.8759 - val_loss: 0.3475 - val_accuracy: 0.8458\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3241 - accuracy: 0.8711 - val_loss: 0.3259 - val_accuracy: 0.8706\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3069 - accuracy: 0.8593 - val_loss: 0.3337 - val_accuracy: 0.8458\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3170 - accuracy: 0.8656 - val_loss: 0.3622 - val_accuracy: 0.8607\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4106 - accuracy: 0.8289 - val_loss: 0.3616 - val_accuracy: 0.8607\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2582 - accuracy: 0.9018 - val_loss: 0.3304 - val_accuracy: 0.8806\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3018 - accuracy: 0.8798 - val_loss: 0.3215 - val_accuracy: 0.8856\n",
            "Score for fold 2: loss of 0.32154545187950134; accuracy of 88.55721354484558%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6640 - accuracy: 0.6469 - val_loss: 0.5798 - val_accuracy: 0.7150\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.6126 - accuracy: 0.6810 - val_loss: 0.5746 - val_accuracy: 0.7150\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5815 - accuracy: 0.7263 - val_loss: 0.5801 - val_accuracy: 0.7250\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.7484 - val_loss: 0.5453 - val_accuracy: 0.7550\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5297 - accuracy: 0.7680 - val_loss: 0.5131 - val_accuracy: 0.7400\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5050 - accuracy: 0.7703 - val_loss: 0.5028 - val_accuracy: 0.7450\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5079 - accuracy: 0.7619 - val_loss: 0.5403 - val_accuracy: 0.7100\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4819 - accuracy: 0.7645 - val_loss: 0.4891 - val_accuracy: 0.7300\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4809 - accuracy: 0.7793 - val_loss: 0.4681 - val_accuracy: 0.7450\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4476 - accuracy: 0.7801 - val_loss: 0.4850 - val_accuracy: 0.7450\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.7942 - val_loss: 0.4607 - val_accuracy: 0.7400\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4384 - accuracy: 0.7764 - val_loss: 0.4551 - val_accuracy: 0.7850\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4802 - accuracy: 0.7672 - val_loss: 0.4682 - val_accuracy: 0.7500\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4586 - accuracy: 0.8028 - val_loss: 0.4660 - val_accuracy: 0.7600\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4444 - accuracy: 0.8114 - val_loss: 0.4545 - val_accuracy: 0.7700\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4340 - accuracy: 0.8044 - val_loss: 0.4463 - val_accuracy: 0.7800\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4594 - accuracy: 0.7913 - val_loss: 0.4255 - val_accuracy: 0.7750\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4135 - accuracy: 0.8067 - val_loss: 0.4136 - val_accuracy: 0.7950\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3802 - accuracy: 0.8266 - val_loss: 0.4652 - val_accuracy: 0.7700\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4029 - accuracy: 0.8169 - val_loss: 0.4159 - val_accuracy: 0.7600\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3857 - accuracy: 0.8189 - val_loss: 0.3797 - val_accuracy: 0.7900\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4122 - accuracy: 0.8087 - val_loss: 0.4102 - val_accuracy: 0.7850\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3664 - accuracy: 0.8396 - val_loss: 0.4966 - val_accuracy: 0.7950\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4102 - accuracy: 0.8307 - val_loss: 0.4111 - val_accuracy: 0.8400\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3887 - accuracy: 0.8216 - val_loss: 0.3713 - val_accuracy: 0.8250\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3867 - accuracy: 0.8132 - val_loss: 0.3878 - val_accuracy: 0.8300\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3493 - accuracy: 0.8490 - val_loss: 0.3878 - val_accuracy: 0.8300\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3525 - accuracy: 0.8394 - val_loss: 0.3918 - val_accuracy: 0.7950\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3609 - accuracy: 0.8358 - val_loss: 0.3861 - val_accuracy: 0.7950\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3375 - accuracy: 0.8426 - val_loss: 0.3752 - val_accuracy: 0.8200\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3916 - accuracy: 0.8139 - val_loss: 0.3783 - val_accuracy: 0.8500\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3363 - accuracy: 0.8445 - val_loss: 0.3765 - val_accuracy: 0.8100\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3385 - accuracy: 0.8453 - val_loss: 0.4213 - val_accuracy: 0.8050\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3504 - accuracy: 0.8435 - val_loss: 0.3383 - val_accuracy: 0.8400\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3093 - accuracy: 0.8743 - val_loss: 0.3516 - val_accuracy: 0.8500\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3206 - accuracy: 0.8618 - val_loss: 0.3717 - val_accuracy: 0.8550\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3416 - accuracy: 0.8670 - val_loss: 0.3306 - val_accuracy: 0.8350\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3209 - accuracy: 0.8544 - val_loss: 0.3184 - val_accuracy: 0.8650\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3189 - accuracy: 0.8833 - val_loss: 0.3340 - val_accuracy: 0.8400\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3549 - accuracy: 0.8428 - val_loss: 0.3474 - val_accuracy: 0.8450\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3106 - accuracy: 0.8554 - val_loss: 0.3544 - val_accuracy: 0.8650\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3317 - accuracy: 0.8632 - val_loss: 0.3247 - val_accuracy: 0.8750\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2933 - accuracy: 0.8565 - val_loss: 0.3109 - val_accuracy: 0.8650\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3347 - accuracy: 0.8608 - val_loss: 0.3589 - val_accuracy: 0.8150\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3405 - accuracy: 0.8533 - val_loss: 0.3097 - val_accuracy: 0.8650\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3015 - accuracy: 0.8619 - val_loss: 0.3517 - val_accuracy: 0.8500\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3406 - accuracy: 0.8546 - val_loss: 0.3846 - val_accuracy: 0.8450\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2912 - accuracy: 0.8902 - val_loss: 0.3026 - val_accuracy: 0.8550\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3521 - accuracy: 0.8751 - val_loss: 0.3046 - val_accuracy: 0.8600\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3408 - accuracy: 0.8545 - val_loss: 0.3371 - val_accuracy: 0.8400\n",
            "Score for fold 3: loss of 0.3370612859725952; accuracy of 83.99999737739563%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6799 - accuracy: 0.5985 - val_loss: 0.5986 - val_accuracy: 0.6800\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.6158 - accuracy: 0.7149 - val_loss: 0.6171 - val_accuracy: 0.7300\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.6141 - accuracy: 0.6772 - val_loss: 0.6064 - val_accuracy: 0.7000\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.6014 - accuracy: 0.6934 - val_loss: 0.5478 - val_accuracy: 0.7200\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5526 - accuracy: 0.7356 - val_loss: 0.4833 - val_accuracy: 0.7700\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5507 - accuracy: 0.7472 - val_loss: 0.4669 - val_accuracy: 0.7450\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5200 - accuracy: 0.7531 - val_loss: 0.4781 - val_accuracy: 0.7500\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4983 - accuracy: 0.7393 - val_loss: 0.4466 - val_accuracy: 0.7850\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4648 - accuracy: 0.7845 - val_loss: 0.3975 - val_accuracy: 0.7750\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4913 - accuracy: 0.7396 - val_loss: 0.4309 - val_accuracy: 0.8200\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4510 - accuracy: 0.7886 - val_loss: 0.3916 - val_accuracy: 0.8100\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4785 - accuracy: 0.7756 - val_loss: 0.4737 - val_accuracy: 0.7650\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4847 - accuracy: 0.7819 - val_loss: 0.3795 - val_accuracy: 0.8050\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4812 - accuracy: 0.7881 - val_loss: 0.3982 - val_accuracy: 0.8000\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4798 - accuracy: 0.7710 - val_loss: 0.4106 - val_accuracy: 0.8150\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4054 - accuracy: 0.8399 - val_loss: 0.4141 - val_accuracy: 0.7500\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.3911 - val_accuracy: 0.8350\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.7843 - val_loss: 0.3536 - val_accuracy: 0.8200\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.7904 - val_loss: 0.3466 - val_accuracy: 0.8300\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4434 - accuracy: 0.8008 - val_loss: 0.3884 - val_accuracy: 0.7750\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4414 - accuracy: 0.7753 - val_loss: 0.3482 - val_accuracy: 0.8450\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3871 - accuracy: 0.8271 - val_loss: 0.3755 - val_accuracy: 0.8300\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4014 - accuracy: 0.8176 - val_loss: 0.3884 - val_accuracy: 0.7750\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4094 - accuracy: 0.8199 - val_loss: 0.3553 - val_accuracy: 0.8550\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3869 - accuracy: 0.8074 - val_loss: 0.3750 - val_accuracy: 0.8100\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3912 - accuracy: 0.8233 - val_loss: 0.3620 - val_accuracy: 0.8200\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3702 - accuracy: 0.8344 - val_loss: 0.3685 - val_accuracy: 0.8400\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3569 - accuracy: 0.8578 - val_loss: 0.3428 - val_accuracy: 0.8750\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3706 - accuracy: 0.8463 - val_loss: 0.3544 - val_accuracy: 0.8400\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4158 - accuracy: 0.8490 - val_loss: 0.3521 - val_accuracy: 0.8350\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3517 - accuracy: 0.8339 - val_loss: 0.3377 - val_accuracy: 0.8200\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3361 - accuracy: 0.8657 - val_loss: 0.3097 - val_accuracy: 0.8600\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4008 - accuracy: 0.8144 - val_loss: 0.3688 - val_accuracy: 0.8650\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3577 - accuracy: 0.8380 - val_loss: 0.3121 - val_accuracy: 0.8500\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3492 - accuracy: 0.8472 - val_loss: 0.3320 - val_accuracy: 0.8850\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3459 - accuracy: 0.8469 - val_loss: 0.3092 - val_accuracy: 0.8600\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3979 - accuracy: 0.8089 - val_loss: 0.3421 - val_accuracy: 0.8400\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3327 - accuracy: 0.8493 - val_loss: 0.3390 - val_accuracy: 0.8400\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3253 - accuracy: 0.8851 - val_loss: 0.3349 - val_accuracy: 0.8150\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3008 - accuracy: 0.8808 - val_loss: 0.3310 - val_accuracy: 0.8500\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3259 - accuracy: 0.8497 - val_loss: 0.3445 - val_accuracy: 0.8450\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2992 - accuracy: 0.8593 - val_loss: 0.3163 - val_accuracy: 0.8600\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2991 - accuracy: 0.8686 - val_loss: 0.3309 - val_accuracy: 0.8300\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3099 - accuracy: 0.8614 - val_loss: 0.2956 - val_accuracy: 0.8900\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2983 - accuracy: 0.8898 - val_loss: 0.3803 - val_accuracy: 0.8400\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3328 - accuracy: 0.8609 - val_loss: 0.3135 - val_accuracy: 0.8400\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3157 - accuracy: 0.8698 - val_loss: 0.3058 - val_accuracy: 0.8650\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2951 - accuracy: 0.8727 - val_loss: 0.2992 - val_accuracy: 0.8750\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2872 - accuracy: 0.8744 - val_loss: 0.2984 - val_accuracy: 0.9000\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2648 - accuracy: 0.8916 - val_loss: 0.2863 - val_accuracy: 0.8700\n",
            "Score for fold 4: loss of 0.2862700819969177; accuracy of 87.00000047683716%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.6557 - accuracy: 0.6462 - val_loss: 0.6360 - val_accuracy: 0.6350\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6228 - accuracy: 0.7102 - val_loss: 0.6159 - val_accuracy: 0.7000\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5625 - accuracy: 0.7322 - val_loss: 0.5938 - val_accuracy: 0.6950\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5639 - accuracy: 0.7219 - val_loss: 0.5533 - val_accuracy: 0.6900\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.5481 - accuracy: 0.7415 - val_loss: 0.6151 - val_accuracy: 0.6850\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5432 - accuracy: 0.7357 - val_loss: 0.5084 - val_accuracy: 0.7250\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5070 - accuracy: 0.7582 - val_loss: 0.4933 - val_accuracy: 0.7600\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7421 - val_loss: 0.5251 - val_accuracy: 0.7100\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.4986 - accuracy: 0.7699 - val_loss: 0.4977 - val_accuracy: 0.7300\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5151 - accuracy: 0.7581 - val_loss: 0.4946 - val_accuracy: 0.7400\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4772 - accuracy: 0.7822 - val_loss: 0.4443 - val_accuracy: 0.8050\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4682 - accuracy: 0.7687 - val_loss: 0.4519 - val_accuracy: 0.7600\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4599 - accuracy: 0.7961 - val_loss: 0.4884 - val_accuracy: 0.8000\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8063 - val_loss: 0.4393 - val_accuracy: 0.8200\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.7883 - val_loss: 0.4609 - val_accuracy: 0.7650\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4451 - accuracy: 0.7969 - val_loss: 0.4391 - val_accuracy: 0.7950\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3964 - accuracy: 0.8351 - val_loss: 0.4108 - val_accuracy: 0.8250\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4230 - accuracy: 0.7929 - val_loss: 0.4224 - val_accuracy: 0.8050\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3666 - accuracy: 0.8548 - val_loss: 0.4103 - val_accuracy: 0.7900\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4010 - accuracy: 0.7790 - val_loss: 0.4138 - val_accuracy: 0.8300\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4113 - accuracy: 0.8055 - val_loss: 0.3949 - val_accuracy: 0.8150\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4032 - accuracy: 0.8076 - val_loss: 0.4672 - val_accuracy: 0.8200\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4545 - accuracy: 0.8162 - val_loss: 0.4218 - val_accuracy: 0.7850\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.8373 - val_loss: 0.4329 - val_accuracy: 0.7900\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4064 - accuracy: 0.8190 - val_loss: 0.4675 - val_accuracy: 0.8050\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.4066 - accuracy: 0.8084 - val_loss: 0.3756 - val_accuracy: 0.8150\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3609 - accuracy: 0.8348 - val_loss: 0.4110 - val_accuracy: 0.7850\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3524 - accuracy: 0.8394 - val_loss: 0.4238 - val_accuracy: 0.8100\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3073 - accuracy: 0.8723 - val_loss: 0.3976 - val_accuracy: 0.8050\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3258 - accuracy: 0.8660 - val_loss: 0.3937 - val_accuracy: 0.7750\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3672 - accuracy: 0.8511 - val_loss: 0.3855 - val_accuracy: 0.8250\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3234 - accuracy: 0.8624 - val_loss: 0.3850 - val_accuracy: 0.8300\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3340 - accuracy: 0.8468 - val_loss: 0.3772 - val_accuracy: 0.8250\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3353 - accuracy: 0.8372 - val_loss: 0.4028 - val_accuracy: 0.8250\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.3183 - accuracy: 0.8856 - val_loss: 0.3789 - val_accuracy: 0.8050\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2997 - accuracy: 0.8699 - val_loss: 0.3886 - val_accuracy: 0.8150\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3100 - accuracy: 0.8649 - val_loss: 0.4044 - val_accuracy: 0.8250\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3386 - accuracy: 0.8483 - val_loss: 0.4060 - val_accuracy: 0.8450\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3530 - accuracy: 0.8368 - val_loss: 0.3740 - val_accuracy: 0.8050\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3518 - accuracy: 0.8428 - val_loss: 0.3742 - val_accuracy: 0.8400\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3482 - accuracy: 0.8485 - val_loss: 0.4044 - val_accuracy: 0.8200\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3296 - accuracy: 0.8520 - val_loss: 0.4656 - val_accuracy: 0.8100\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3406 - accuracy: 0.8746 - val_loss: 0.3696 - val_accuracy: 0.8550\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3223 - accuracy: 0.8636 - val_loss: 0.4301 - val_accuracy: 0.8200\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2923 - accuracy: 0.8775 - val_loss: 0.4006 - val_accuracy: 0.8300\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2816 - accuracy: 0.8754 - val_loss: 0.3578 - val_accuracy: 0.8350\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2921 - accuracy: 0.8649 - val_loss: 0.3568 - val_accuracy: 0.8350\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.2438 - accuracy: 0.9001 - val_loss: 0.3461 - val_accuracy: 0.8300\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2588 - accuracy: 0.8943 - val_loss: 0.4118 - val_accuracy: 0.8450\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.2846 - accuracy: 0.8754 - val_loss: 0.3470 - val_accuracy: 0.8350\n",
            "Score for fold 5: loss of 0.3469681143760681; accuracy of 83.49999785423279%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.42478278279304504 - Accuracy: 83.08457732200623%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.32154545187950134 - Accuracy: 88.55721354484558%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.3370612859725952 - Accuracy: 83.99999737739563%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.2862700819969177 - Accuracy: 87.00000047683716%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.3469681143760681 - Accuracy: 83.49999785423279%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 85.22835731506348 (+- 2.1592540615759614)\n",
            "> Loss: 0.3433255434036255\n",
            "------------------------------------------------------------------------\n",
            "(696, 6, 1, 1)\n",
            "(696, 2)\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6956 - accuracy: 0.5421 - val_loss: 0.6391 - val_accuracy: 0.6269\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6392 - accuracy: 0.6631 - val_loss: 0.6190 - val_accuracy: 0.6617\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.6292 - accuracy: 0.6834 - val_loss: 0.5751 - val_accuracy: 0.6766\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.5781 - accuracy: 0.7050 - val_loss: 0.5532 - val_accuracy: 0.7313\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.5872 - accuracy: 0.6826 - val_loss: 0.5399 - val_accuracy: 0.7313\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5742 - accuracy: 0.7389 - val_loss: 0.5703 - val_accuracy: 0.7313\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.5535 - accuracy: 0.7408 - val_loss: 0.5644 - val_accuracy: 0.7264\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5340 - accuracy: 0.7579 - val_loss: 0.5724 - val_accuracy: 0.7264\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5484 - accuracy: 0.7434 - val_loss: 0.5156 - val_accuracy: 0.7612\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4917 - accuracy: 0.7787 - val_loss: 0.4834 - val_accuracy: 0.7612\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5108 - accuracy: 0.7779 - val_loss: 0.5237 - val_accuracy: 0.7761\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5115 - accuracy: 0.7510 - val_loss: 0.4739 - val_accuracy: 0.7612\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5225 - accuracy: 0.7504 - val_loss: 0.4544 - val_accuracy: 0.8060\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4879 - accuracy: 0.8045 - val_loss: 0.4713 - val_accuracy: 0.7761\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5120 - accuracy: 0.7670 - val_loss: 0.4804 - val_accuracy: 0.7960\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4962 - accuracy: 0.7625 - val_loss: 0.4449 - val_accuracy: 0.7960\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.4672 - accuracy: 0.7816 - val_loss: 0.4708 - val_accuracy: 0.7861\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4588 - accuracy: 0.8067 - val_loss: 0.4703 - val_accuracy: 0.8010\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4448 - accuracy: 0.8307 - val_loss: 0.4723 - val_accuracy: 0.8010\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4910 - accuracy: 0.7711 - val_loss: 0.4502 - val_accuracy: 0.7910\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4390 - accuracy: 0.7672 - val_loss: 0.4416 - val_accuracy: 0.7910\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4693 - accuracy: 0.7799 - val_loss: 0.4583 - val_accuracy: 0.8060\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4598 - accuracy: 0.8131 - val_loss: 0.4273 - val_accuracy: 0.8060\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.4417 - accuracy: 0.7886 - val_loss: 0.4393 - val_accuracy: 0.7711\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.8028 - val_loss: 0.4394 - val_accuracy: 0.7861\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4034 - accuracy: 0.8218 - val_loss: 0.4396 - val_accuracy: 0.7662\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4350 - accuracy: 0.8034 - val_loss: 0.4102 - val_accuracy: 0.7960\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4699 - accuracy: 0.7895 - val_loss: 0.4180 - val_accuracy: 0.8109\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3976 - accuracy: 0.8349 - val_loss: 0.4484 - val_accuracy: 0.8109\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3912 - accuracy: 0.8312 - val_loss: 0.3734 - val_accuracy: 0.8159\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4314 - accuracy: 0.8058 - val_loss: 0.4679 - val_accuracy: 0.7811\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.7970 - val_loss: 0.4085 - val_accuracy: 0.7960\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.3964 - accuracy: 0.8001 - val_loss: 0.4060 - val_accuracy: 0.8209\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4139 - accuracy: 0.8295 - val_loss: 0.3792 - val_accuracy: 0.8308\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4004 - accuracy: 0.8268 - val_loss: 0.4266 - val_accuracy: 0.8209\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.4505 - accuracy: 0.7977 - val_loss: 0.4134 - val_accuracy: 0.8109\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.3969 - accuracy: 0.8312 - val_loss: 0.4102 - val_accuracy: 0.7960\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4168 - accuracy: 0.7933 - val_loss: 0.4062 - val_accuracy: 0.7761\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4121 - accuracy: 0.8258 - val_loss: 0.3743 - val_accuracy: 0.8109\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4157 - accuracy: 0.8124 - val_loss: 0.4067 - val_accuracy: 0.7960\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4021 - accuracy: 0.8035 - val_loss: 0.3774 - val_accuracy: 0.8209\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3606 - accuracy: 0.8399 - val_loss: 0.4083 - val_accuracy: 0.8010\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3931 - accuracy: 0.8268 - val_loss: 0.3837 - val_accuracy: 0.8010\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3997 - accuracy: 0.8186 - val_loss: 0.4311 - val_accuracy: 0.8010\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4089 - accuracy: 0.8143 - val_loss: 0.3909 - val_accuracy: 0.8209\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3995 - accuracy: 0.8051 - val_loss: 0.4163 - val_accuracy: 0.7960\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3930 - accuracy: 0.8335 - val_loss: 0.4907 - val_accuracy: 0.7910\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3996 - accuracy: 0.8298 - val_loss: 0.3866 - val_accuracy: 0.8209\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3707 - accuracy: 0.8366 - val_loss: 0.4097 - val_accuracy: 0.7960\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.3639 - accuracy: 0.8153 - val_loss: 0.3583 - val_accuracy: 0.8259\n",
            "Score for fold 1: loss of 0.35832709074020386; accuracy of 82.58706331253052%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6887 - accuracy: 0.5228 - val_loss: 0.6257 - val_accuracy: 0.6965\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6236 - accuracy: 0.6584 - val_loss: 0.5988 - val_accuracy: 0.6816\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.6536 - accuracy: 0.6224 - val_loss: 0.5519 - val_accuracy: 0.7512\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5869 - accuracy: 0.6739 - val_loss: 0.5516 - val_accuracy: 0.7811\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5582 - accuracy: 0.7370 - val_loss: 0.5236 - val_accuracy: 0.7960\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.5801 - accuracy: 0.7034 - val_loss: 0.5012 - val_accuracy: 0.7910\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5729 - accuracy: 0.6954 - val_loss: 0.4753 - val_accuracy: 0.7711\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5326 - accuracy: 0.7488 - val_loss: 0.5119 - val_accuracy: 0.7612\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.5537 - accuracy: 0.7146 - val_loss: 0.4308 - val_accuracy: 0.8259\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.5600 - accuracy: 0.7121 - val_loss: 0.4695 - val_accuracy: 0.8060\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5168 - accuracy: 0.7399 - val_loss: 0.4848 - val_accuracy: 0.7413\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.5475 - accuracy: 0.7386 - val_loss: 0.4432 - val_accuracy: 0.8109\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4810 - accuracy: 0.7960 - val_loss: 0.5240 - val_accuracy: 0.7910\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.5301 - accuracy: 0.7344 - val_loss: 0.5354 - val_accuracy: 0.7612\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4856 - accuracy: 0.7785 - val_loss: 0.4804 - val_accuracy: 0.7960\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.5112 - accuracy: 0.7495 - val_loss: 0.4918 - val_accuracy: 0.7662\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5161 - accuracy: 0.7384 - val_loss: 0.4262 - val_accuracy: 0.8458\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5043 - accuracy: 0.7668 - val_loss: 0.4198 - val_accuracy: 0.8209\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4911 - accuracy: 0.7754 - val_loss: 0.4298 - val_accuracy: 0.8060\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4818 - accuracy: 0.7866 - val_loss: 0.4618 - val_accuracy: 0.7861\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5384 - accuracy: 0.7555 - val_loss: 0.4041 - val_accuracy: 0.8557\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4586 - accuracy: 0.7932 - val_loss: 0.4238 - val_accuracy: 0.8408\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4664 - accuracy: 0.7854 - val_loss: 0.4355 - val_accuracy: 0.8060\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4490 - accuracy: 0.7797 - val_loss: 0.4073 - val_accuracy: 0.8259\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4694 - accuracy: 0.7730 - val_loss: 0.4214 - val_accuracy: 0.8259\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.4745 - accuracy: 0.7659 - val_loss: 0.3996 - val_accuracy: 0.8209\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4536 - accuracy: 0.7862 - val_loss: 0.4173 - val_accuracy: 0.8060\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4754 - accuracy: 0.7675 - val_loss: 0.4147 - val_accuracy: 0.7861\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4675 - accuracy: 0.7755 - val_loss: 0.4094 - val_accuracy: 0.8259\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4340 - accuracy: 0.7854 - val_loss: 0.3926 - val_accuracy: 0.8308\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4481 - accuracy: 0.7876 - val_loss: 0.4145 - val_accuracy: 0.8209\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.3894 - accuracy: 0.8306 - val_loss: 0.4192 - val_accuracy: 0.8109\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.4302 - accuracy: 0.7951 - val_loss: 0.3756 - val_accuracy: 0.8159\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.7946 - val_loss: 0.3964 - val_accuracy: 0.8308\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3825 - accuracy: 0.8180 - val_loss: 0.4118 - val_accuracy: 0.8308\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.3705 - val_accuracy: 0.8408\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4176 - accuracy: 0.7990 - val_loss: 0.3966 - val_accuracy: 0.8458\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.4095 - accuracy: 0.8174 - val_loss: 0.3878 - val_accuracy: 0.8010\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4167 - accuracy: 0.8078 - val_loss: 0.3422 - val_accuracy: 0.8159\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4097 - accuracy: 0.8161 - val_loss: 0.4196 - val_accuracy: 0.8209\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.8143 - val_loss: 0.4015 - val_accuracy: 0.8109\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4244 - accuracy: 0.7762 - val_loss: 0.3769 - val_accuracy: 0.8109\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4090 - accuracy: 0.7971 - val_loss: 0.3896 - val_accuracy: 0.7711\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4062 - accuracy: 0.7810 - val_loss: 0.3596 - val_accuracy: 0.8159\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4753 - accuracy: 0.7959 - val_loss: 0.4174 - val_accuracy: 0.7960\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4130 - accuracy: 0.8020 - val_loss: 0.3719 - val_accuracy: 0.8458\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4079 - accuracy: 0.8077 - val_loss: 0.4166 - val_accuracy: 0.8060\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.7740 - val_loss: 0.3690 - val_accuracy: 0.8308\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4003 - accuracy: 0.8414 - val_loss: 0.4673 - val_accuracy: 0.8159\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4228 - accuracy: 0.8084 - val_loss: 0.4337 - val_accuracy: 0.8060\n",
            "Score for fold 2: loss of 0.4336759150028229; accuracy of 80.59701323509216%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.6937 - accuracy: 0.5920 - val_loss: 0.6137 - val_accuracy: 0.6850\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6479 - accuracy: 0.6250 - val_loss: 0.5777 - val_accuracy: 0.6650\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6077 - accuracy: 0.7041 - val_loss: 0.5724 - val_accuracy: 0.6850\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5822 - accuracy: 0.6796 - val_loss: 0.5659 - val_accuracy: 0.6800\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5758 - accuracy: 0.7388 - val_loss: 0.6085 - val_accuracy: 0.6950\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5689 - accuracy: 0.7361 - val_loss: 0.5215 - val_accuracy: 0.7350\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5341 - accuracy: 0.7622 - val_loss: 0.5372 - val_accuracy: 0.7250\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5498 - accuracy: 0.7480 - val_loss: 0.5680 - val_accuracy: 0.6600\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.5256 - accuracy: 0.7549 - val_loss: 0.5500 - val_accuracy: 0.6450\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5161 - accuracy: 0.7733 - val_loss: 0.6052 - val_accuracy: 0.6950\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4997 - accuracy: 0.7791 - val_loss: 0.5034 - val_accuracy: 0.7300\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4567 - accuracy: 0.8020 - val_loss: 0.5337 - val_accuracy: 0.7250\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4976 - accuracy: 0.7675 - val_loss: 0.5336 - val_accuracy: 0.7150\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5397 - accuracy: 0.7409 - val_loss: 0.4952 - val_accuracy: 0.7350\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4656 - accuracy: 0.7802 - val_loss: 0.5328 - val_accuracy: 0.7100\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4609 - accuracy: 0.7954 - val_loss: 0.4985 - val_accuracy: 0.7250\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4683 - accuracy: 0.7794 - val_loss: 0.4813 - val_accuracy: 0.7450\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4745 - accuracy: 0.7902 - val_loss: 0.5021 - val_accuracy: 0.7150\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4447 - accuracy: 0.8111 - val_loss: 0.4912 - val_accuracy: 0.7200\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4354 - accuracy: 0.8078 - val_loss: 0.4685 - val_accuracy: 0.7750\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4449 - accuracy: 0.7997 - val_loss: 0.4697 - val_accuracy: 0.7300\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4363 - accuracy: 0.8057 - val_loss: 0.4415 - val_accuracy: 0.7450\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4443 - accuracy: 0.8041 - val_loss: 0.4471 - val_accuracy: 0.7500\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 0.4317 - accuracy: 0.8061 - val_loss: 0.4444 - val_accuracy: 0.7800\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4002 - accuracy: 0.8366 - val_loss: 0.4645 - val_accuracy: 0.7700\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4536 - accuracy: 0.7747 - val_loss: 0.4621 - val_accuracy: 0.7600\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4629 - accuracy: 0.8292 - val_loss: 0.4452 - val_accuracy: 0.7700\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4422 - accuracy: 0.8094 - val_loss: 0.4615 - val_accuracy: 0.7300\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.4396 - val_accuracy: 0.7550\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4099 - accuracy: 0.8267 - val_loss: 0.4531 - val_accuracy: 0.7750\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4002 - accuracy: 0.8260 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4368 - accuracy: 0.8025 - val_loss: 0.4272 - val_accuracy: 0.7850\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4063 - accuracy: 0.8139 - val_loss: 0.4087 - val_accuracy: 0.7850\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3964 - accuracy: 0.8121 - val_loss: 0.4170 - val_accuracy: 0.7750\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3566 - accuracy: 0.8293 - val_loss: 0.4186 - val_accuracy: 0.7600\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3801 - accuracy: 0.8190 - val_loss: 0.4245 - val_accuracy: 0.7450\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4122 - accuracy: 0.8205 - val_loss: 0.4666 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4104 - accuracy: 0.8183 - val_loss: 0.4387 - val_accuracy: 0.7850\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3808 - accuracy: 0.8403 - val_loss: 0.4238 - val_accuracy: 0.7650\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3864 - accuracy: 0.8370 - val_loss: 0.4529 - val_accuracy: 0.7550\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4026 - accuracy: 0.8206 - val_loss: 0.4539 - val_accuracy: 0.7800\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4233 - accuracy: 0.8119 - val_loss: 0.4394 - val_accuracy: 0.7650\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3468 - accuracy: 0.8442 - val_loss: 0.3988 - val_accuracy: 0.8050\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3868 - accuracy: 0.8245 - val_loss: 0.4491 - val_accuracy: 0.7700\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4388 - accuracy: 0.8078 - val_loss: 0.4107 - val_accuracy: 0.7750\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3680 - accuracy: 0.8122 - val_loss: 0.3835 - val_accuracy: 0.7800\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3328 - accuracy: 0.8517 - val_loss: 0.3862 - val_accuracy: 0.7800\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3663 - accuracy: 0.8396 - val_loss: 0.4156 - val_accuracy: 0.7600\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3711 - accuracy: 0.8334 - val_loss: 0.3711 - val_accuracy: 0.8150\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3676 - accuracy: 0.8419 - val_loss: 0.3696 - val_accuracy: 0.7950\n",
            "Score for fold 3: loss of 0.36960625648498535; accuracy of 79.50000166893005%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.6842 - accuracy: 0.5875 - val_loss: 0.6489 - val_accuracy: 0.6050\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6134 - accuracy: 0.6778 - val_loss: 0.6467 - val_accuracy: 0.6500\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5965 - accuracy: 0.7145 - val_loss: 0.6496 - val_accuracy: 0.6600\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5642 - accuracy: 0.7041 - val_loss: 0.6055 - val_accuracy: 0.7100\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5610 - accuracy: 0.7277 - val_loss: 0.6101 - val_accuracy: 0.6650\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5831 - accuracy: 0.7165 - val_loss: 0.5974 - val_accuracy: 0.6850\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5591 - accuracy: 0.7262 - val_loss: 0.5684 - val_accuracy: 0.7350\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4995 - accuracy: 0.7745 - val_loss: 0.5389 - val_accuracy: 0.7200\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5191 - accuracy: 0.7809 - val_loss: 0.5189 - val_accuracy: 0.7450\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5318 - accuracy: 0.7559 - val_loss: 0.5394 - val_accuracy: 0.7050\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4984 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7300\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4438 - accuracy: 0.8202 - val_loss: 0.5187 - val_accuracy: 0.7050\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4809 - accuracy: 0.7734 - val_loss: 0.5204 - val_accuracy: 0.7450\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4880 - accuracy: 0.7818 - val_loss: 0.5052 - val_accuracy: 0.7350\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4855 - accuracy: 0.7611 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4992 - accuracy: 0.7876 - val_loss: 0.4578 - val_accuracy: 0.7550\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4792 - accuracy: 0.7912 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4734 - accuracy: 0.7876 - val_loss: 0.4613 - val_accuracy: 0.7550\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4745 - accuracy: 0.7998 - val_loss: 0.5617 - val_accuracy: 0.7500\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.4604 - val_accuracy: 0.7550\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4253 - accuracy: 0.7893 - val_loss: 0.5023 - val_accuracy: 0.7600\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4183 - accuracy: 0.8116 - val_loss: 0.4746 - val_accuracy: 0.7400\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4447 - accuracy: 0.7904 - val_loss: 0.4689 - val_accuracy: 0.7400\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.4588 - accuracy: 0.7921 - val_loss: 0.4426 - val_accuracy: 0.7650\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4326 - accuracy: 0.8008 - val_loss: 0.4383 - val_accuracy: 0.7750\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4101 - accuracy: 0.7878 - val_loss: 0.4573 - val_accuracy: 0.7750\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4488 - accuracy: 0.7813 - val_loss: 0.4235 - val_accuracy: 0.7900\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4354 - accuracy: 0.8134 - val_loss: 0.4263 - val_accuracy: 0.7650\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4319 - accuracy: 0.7875 - val_loss: 0.4380 - val_accuracy: 0.7800\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4333 - accuracy: 0.8044 - val_loss: 0.4618 - val_accuracy: 0.7650\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4182 - accuracy: 0.7765 - val_loss: 0.4378 - val_accuracy: 0.7750\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3797 - accuracy: 0.8203 - val_loss: 0.4270 - val_accuracy: 0.7800\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4158 - accuracy: 0.8080 - val_loss: 0.4414 - val_accuracy: 0.7800\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4090 - accuracy: 0.8068 - val_loss: 0.4481 - val_accuracy: 0.7750\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4134 - accuracy: 0.8194 - val_loss: 0.4402 - val_accuracy: 0.7750\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3942 - accuracy: 0.8035 - val_loss: 0.4330 - val_accuracy: 0.7750\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3944 - accuracy: 0.8180 - val_loss: 0.4178 - val_accuracy: 0.7800\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3881 - accuracy: 0.8136 - val_loss: 0.4386 - val_accuracy: 0.7950\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4204 - accuracy: 0.7915 - val_loss: 0.4314 - val_accuracy: 0.7850\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3806 - accuracy: 0.8388 - val_loss: 0.4210 - val_accuracy: 0.8100\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4259 - accuracy: 0.7926 - val_loss: 0.4906 - val_accuracy: 0.7800\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3679 - accuracy: 0.8330 - val_loss: 0.3907 - val_accuracy: 0.7700\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4801 - accuracy: 0.7978 - val_loss: 0.4733 - val_accuracy: 0.7750\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3913 - accuracy: 0.8099 - val_loss: 0.4175 - val_accuracy: 0.7750\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4058 - accuracy: 0.7888 - val_loss: 0.4376 - val_accuracy: 0.7650\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4083 - accuracy: 0.8187 - val_loss: 0.4466 - val_accuracy: 0.7600\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3492 - accuracy: 0.8339 - val_loss: 0.4659 - val_accuracy: 0.7550\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3778 - accuracy: 0.8073 - val_loss: 0.5066 - val_accuracy: 0.7950\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4082 - accuracy: 0.8078 - val_loss: 0.4443 - val_accuracy: 0.8000\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3869 - accuracy: 0.8243 - val_loss: 0.4028 - val_accuracy: 0.7950\n",
            "Score for fold 4: loss of 0.4028259515762329; accuracy of 79.50000166893005%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.7023 - accuracy: 0.5220 - val_loss: 0.7109 - val_accuracy: 0.5300\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6355 - accuracy: 0.6373 - val_loss: 0.6092 - val_accuracy: 0.6800\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6152 - accuracy: 0.6671 - val_loss: 0.6157 - val_accuracy: 0.7400\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5791 - accuracy: 0.6867 - val_loss: 0.5771 - val_accuracy: 0.7450\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5829 - accuracy: 0.7229 - val_loss: 0.5612 - val_accuracy: 0.7250\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5552 - accuracy: 0.7043 - val_loss: 0.6507 - val_accuracy: 0.7000\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5924 - accuracy: 0.6886 - val_loss: 0.5282 - val_accuracy: 0.7350\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5324 - accuracy: 0.7048 - val_loss: 0.5210 - val_accuracy: 0.7700\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5271 - accuracy: 0.7451 - val_loss: 0.5248 - val_accuracy: 0.7650\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5054 - accuracy: 0.7632 - val_loss: 0.5397 - val_accuracy: 0.7550\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5420 - accuracy: 0.7341 - val_loss: 0.4954 - val_accuracy: 0.7350\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.5230 - accuracy: 0.7533 - val_loss: 0.5446 - val_accuracy: 0.7400\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4888 - accuracy: 0.7503 - val_loss: 0.4893 - val_accuracy: 0.7950\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5017 - accuracy: 0.7275 - val_loss: 0.5351 - val_accuracy: 0.7450\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4571 - accuracy: 0.7738 - val_loss: 0.4894 - val_accuracy: 0.7750\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5025 - accuracy: 0.7941 - val_loss: 0.4951 - val_accuracy: 0.7550\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4747 - accuracy: 0.7667 - val_loss: 0.4845 - val_accuracy: 0.7900\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4791 - accuracy: 0.7680 - val_loss: 0.4985 - val_accuracy: 0.7700\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4663 - accuracy: 0.7696 - val_loss: 0.5011 - val_accuracy: 0.7550\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4640 - accuracy: 0.7807 - val_loss: 0.4594 - val_accuracy: 0.8000\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4646 - accuracy: 0.7843 - val_loss: 0.4993 - val_accuracy: 0.7900\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4462 - accuracy: 0.7924 - val_loss: 0.5748 - val_accuracy: 0.7700\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4409 - accuracy: 0.7970 - val_loss: 0.4621 - val_accuracy: 0.7850\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4065 - accuracy: 0.8252 - val_loss: 0.5247 - val_accuracy: 0.7600\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4105 - accuracy: 0.8103 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4165 - accuracy: 0.7917 - val_loss: 0.4388 - val_accuracy: 0.8050\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4299 - accuracy: 0.8210 - val_loss: 0.4614 - val_accuracy: 0.8200\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4287 - accuracy: 0.7791 - val_loss: 0.4956 - val_accuracy: 0.7950\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4268 - accuracy: 0.8060 - val_loss: 0.4572 - val_accuracy: 0.7900\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4692 - accuracy: 0.8069 - val_loss: 0.4563 - val_accuracy: 0.7850\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4179 - accuracy: 0.8043 - val_loss: 0.4508 - val_accuracy: 0.7900\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3813 - accuracy: 0.8269 - val_loss: 0.4478 - val_accuracy: 0.7950\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3780 - accuracy: 0.8224 - val_loss: 0.4830 - val_accuracy: 0.8000\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4443 - accuracy: 0.8022 - val_loss: 0.4126 - val_accuracy: 0.8050\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4024 - accuracy: 0.8120 - val_loss: 0.4778 - val_accuracy: 0.8150\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3782 - accuracy: 0.8460 - val_loss: 0.4631 - val_accuracy: 0.8050\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3544 - accuracy: 0.8639 - val_loss: 0.5048 - val_accuracy: 0.7750\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3943 - accuracy: 0.8423 - val_loss: 0.4355 - val_accuracy: 0.8100\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4064 - accuracy: 0.8058 - val_loss: 0.4820 - val_accuracy: 0.7850\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3928 - accuracy: 0.8134 - val_loss: 0.4291 - val_accuracy: 0.8050\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3813 - accuracy: 0.8132 - val_loss: 0.4813 - val_accuracy: 0.8250\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3605 - accuracy: 0.8317 - val_loss: 0.4690 - val_accuracy: 0.8300\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3624 - accuracy: 0.8292 - val_loss: 0.5070 - val_accuracy: 0.8000\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3970 - accuracy: 0.8122 - val_loss: 0.5607 - val_accuracy: 0.7950\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4296 - accuracy: 0.8191 - val_loss: 0.5015 - val_accuracy: 0.8150\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3314 - accuracy: 0.8491 - val_loss: 0.4331 - val_accuracy: 0.8200\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3550 - accuracy: 0.8340 - val_loss: 0.5530 - val_accuracy: 0.7750\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3919 - accuracy: 0.8339 - val_loss: 0.4428 - val_accuracy: 0.7950\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3893 - accuracy: 0.8008 - val_loss: 0.4895 - val_accuracy: 0.7850\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3935 - accuracy: 0.8217 - val_loss: 0.4651 - val_accuracy: 0.8200\n",
            "Score for fold 5: loss of 0.4651290476322174; accuracy of 81.99999928474426%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.35832709074020386 - Accuracy: 82.58706331253052%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.4336759150028229 - Accuracy: 80.59701323509216%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.36960625648498535 - Accuracy: 79.50000166893005%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.4028259515762329 - Accuracy: 79.50000166893005%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.4651290476322174 - Accuracy: 81.99999928474426%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 80.83681583404541 (+- 1.2687010275469972)\n",
            "> Loss: 0.40591285228729246\n",
            "------------------------------------------------------------------------\n",
            "(696, 6, 1, 1)\n",
            "(696, 2)\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_40 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.6920 - accuracy: 0.5668 - val_loss: 0.5942 - val_accuracy: 0.7015\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.6182 - accuracy: 0.6468 - val_loss: 0.5121 - val_accuracy: 0.7612\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5572 - accuracy: 0.7069 - val_loss: 0.5070 - val_accuracy: 0.7761\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5371 - accuracy: 0.7232 - val_loss: 0.4515 - val_accuracy: 0.7612\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5333 - accuracy: 0.7488 - val_loss: 0.5080 - val_accuracy: 0.7711\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4972 - accuracy: 0.7710 - val_loss: 0.4267 - val_accuracy: 0.8109\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4997 - accuracy: 0.7164 - val_loss: 0.4256 - val_accuracy: 0.8358\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4767 - accuracy: 0.7518 - val_loss: 0.4012 - val_accuracy: 0.8010\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4998 - accuracy: 0.7407 - val_loss: 0.4027 - val_accuracy: 0.8109\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4418 - accuracy: 0.7842 - val_loss: 0.4414 - val_accuracy: 0.8159\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4320 - accuracy: 0.7796 - val_loss: 0.4063 - val_accuracy: 0.8259\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4113 - accuracy: 0.8030 - val_loss: 0.4021 - val_accuracy: 0.8308\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4427 - accuracy: 0.7762 - val_loss: 0.4559 - val_accuracy: 0.7811\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4294 - accuracy: 0.8130 - val_loss: 0.4172 - val_accuracy: 0.8109\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4110 - accuracy: 0.7900 - val_loss: 0.4028 - val_accuracy: 0.8458\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4552 - accuracy: 0.7956 - val_loss: 0.3858 - val_accuracy: 0.8308\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4050 - accuracy: 0.7803 - val_loss: 0.3840 - val_accuracy: 0.8308\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3816 - accuracy: 0.8207 - val_loss: 0.3711 - val_accuracy: 0.8507\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3948 - accuracy: 0.8087 - val_loss: 0.3883 - val_accuracy: 0.8358\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3789 - accuracy: 0.8248 - val_loss: 0.4078 - val_accuracy: 0.8308\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3680 - accuracy: 0.8189 - val_loss: 0.3884 - val_accuracy: 0.8408\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3673 - accuracy: 0.8369 - val_loss: 0.3874 - val_accuracy: 0.8557\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3529 - accuracy: 0.8565 - val_loss: 0.3925 - val_accuracy: 0.8607\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3133 - accuracy: 0.8600 - val_loss: 0.3716 - val_accuracy: 0.8308\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3604 - accuracy: 0.8333 - val_loss: 0.3500 - val_accuracy: 0.8607\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3115 - accuracy: 0.8535 - val_loss: 0.3539 - val_accuracy: 0.8607\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3591 - accuracy: 0.8488 - val_loss: 0.3763 - val_accuracy: 0.8458\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3373 - accuracy: 0.8526 - val_loss: 0.3619 - val_accuracy: 0.8458\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3105 - accuracy: 0.8671 - val_loss: 0.3497 - val_accuracy: 0.8557\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3314 - accuracy: 0.8483 - val_loss: 0.3633 - val_accuracy: 0.8657\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3150 - accuracy: 0.8369 - val_loss: 0.3797 - val_accuracy: 0.8955\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3339 - accuracy: 0.8580 - val_loss: 0.3704 - val_accuracy: 0.8308\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3408 - accuracy: 0.8485 - val_loss: 0.3605 - val_accuracy: 0.8507\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.2969 - accuracy: 0.8702 - val_loss: 0.3320 - val_accuracy: 0.8706\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3012 - accuracy: 0.8627 - val_loss: 0.3754 - val_accuracy: 0.8856\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2699 - accuracy: 0.8568 - val_loss: 0.3526 - val_accuracy: 0.8657\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3391 - accuracy: 0.8588 - val_loss: 0.3462 - val_accuracy: 0.8607\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3295 - accuracy: 0.8506 - val_loss: 0.3489 - val_accuracy: 0.8557\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3546 - accuracy: 0.8694 - val_loss: 0.3280 - val_accuracy: 0.8657\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2562 - accuracy: 0.8813 - val_loss: 0.3303 - val_accuracy: 0.8806\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3430 - accuracy: 0.8617 - val_loss: 0.3584 - val_accuracy: 0.8856\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2895 - accuracy: 0.8646 - val_loss: 0.3382 - val_accuracy: 0.8856\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3338 - accuracy: 0.8335 - val_loss: 0.3393 - val_accuracy: 0.8706\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2591 - accuracy: 0.9184 - val_loss: 0.3537 - val_accuracy: 0.8507\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3009 - accuracy: 0.8721 - val_loss: 0.3281 - val_accuracy: 0.8657\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2860 - accuracy: 0.8677 - val_loss: 0.3227 - val_accuracy: 0.8607\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2755 - accuracy: 0.8880 - val_loss: 0.3180 - val_accuracy: 0.8955\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2858 - accuracy: 0.8592 - val_loss: 0.3227 - val_accuracy: 0.8856\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2017 - accuracy: 0.9098 - val_loss: 0.3422 - val_accuracy: 0.8856\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2688 - accuracy: 0.8706 - val_loss: 0.3401 - val_accuracy: 0.8706\n",
            "Score for fold 1: loss of 0.3400593400001526; accuracy of 87.06467747688293%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_44 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.6711 - accuracy: 0.6002 - val_loss: 0.5817 - val_accuracy: 0.6915\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6624 - accuracy: 0.6460 - val_loss: 0.5782 - val_accuracy: 0.6766\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5910 - accuracy: 0.6859 - val_loss: 0.5259 - val_accuracy: 0.7114\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5652 - accuracy: 0.6843 - val_loss: 0.5025 - val_accuracy: 0.6866\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4671 - accuracy: 0.7635 - val_loss: 0.4765 - val_accuracy: 0.7910\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4968 - accuracy: 0.7815 - val_loss: 0.4352 - val_accuracy: 0.7960\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4737 - accuracy: 0.7951 - val_loss: 0.4537 - val_accuracy: 0.7861\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5047 - accuracy: 0.7565 - val_loss: 0.4337 - val_accuracy: 0.7960\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4369 - accuracy: 0.7877 - val_loss: 0.4269 - val_accuracy: 0.8060\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4670 - accuracy: 0.7817 - val_loss: 0.4021 - val_accuracy: 0.8209\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4165 - accuracy: 0.7997 - val_loss: 0.4408 - val_accuracy: 0.7960\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4133 - accuracy: 0.8145 - val_loss: 0.4797 - val_accuracy: 0.7811\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4548 - accuracy: 0.8059 - val_loss: 0.3909 - val_accuracy: 0.8060\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4268 - accuracy: 0.8018 - val_loss: 0.4167 - val_accuracy: 0.7960\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4089 - accuracy: 0.8058 - val_loss: 0.4113 - val_accuracy: 0.8259\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3795 - accuracy: 0.8249 - val_loss: 0.3918 - val_accuracy: 0.8159\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3651 - accuracy: 0.8308 - val_loss: 0.3754 - val_accuracy: 0.8308\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4028 - accuracy: 0.8036 - val_loss: 0.3902 - val_accuracy: 0.7960\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4088 - accuracy: 0.8112 - val_loss: 0.3769 - val_accuracy: 0.8308\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3708 - accuracy: 0.8175 - val_loss: 0.3797 - val_accuracy: 0.8060\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3566 - accuracy: 0.8297 - val_loss: 0.3655 - val_accuracy: 0.8308\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3884 - accuracy: 0.8080 - val_loss: 0.3612 - val_accuracy: 0.8209\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3795 - accuracy: 0.8433 - val_loss: 0.3607 - val_accuracy: 0.8408\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3544 - accuracy: 0.8401 - val_loss: 0.3459 - val_accuracy: 0.8308\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3714 - accuracy: 0.8249 - val_loss: 0.3696 - val_accuracy: 0.8159\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3661 - accuracy: 0.8150 - val_loss: 0.3730 - val_accuracy: 0.8358\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3890 - accuracy: 0.7969 - val_loss: 0.4127 - val_accuracy: 0.8109\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3535 - accuracy: 0.8407 - val_loss: 0.3999 - val_accuracy: 0.8060\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3214 - accuracy: 0.8602 - val_loss: 0.3342 - val_accuracy: 0.8358\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3032 - accuracy: 0.8609 - val_loss: 0.3163 - val_accuracy: 0.8358\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3247 - accuracy: 0.8689 - val_loss: 0.3332 - val_accuracy: 0.8458\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3137 - accuracy: 0.8570 - val_loss: 0.3137 - val_accuracy: 0.8507\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3118 - accuracy: 0.8448 - val_loss: 0.3391 - val_accuracy: 0.8507\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3326 - accuracy: 0.8558 - val_loss: 0.3510 - val_accuracy: 0.8209\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2954 - accuracy: 0.8692 - val_loss: 0.3698 - val_accuracy: 0.8507\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2854 - accuracy: 0.8724 - val_loss: 0.3349 - val_accuracy: 0.8557\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3024 - accuracy: 0.8813 - val_loss: 0.3326 - val_accuracy: 0.8607\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3343 - accuracy: 0.8555 - val_loss: 0.3497 - val_accuracy: 0.8657\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3330 - accuracy: 0.8423 - val_loss: 0.3323 - val_accuracy: 0.8458\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2892 - accuracy: 0.8702 - val_loss: 0.3172 - val_accuracy: 0.8806\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2760 - accuracy: 0.8874 - val_loss: 0.3418 - val_accuracy: 0.8308\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2956 - accuracy: 0.8907 - val_loss: 0.3478 - val_accuracy: 0.8657\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2802 - accuracy: 0.8927 - val_loss: 0.3960 - val_accuracy: 0.8308\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.2510 - accuracy: 0.8942 - val_loss: 0.3316 - val_accuracy: 0.8408\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3510 - accuracy: 0.8572 - val_loss: 0.3102 - val_accuracy: 0.8557\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2801 - accuracy: 0.8637 - val_loss: 0.3457 - val_accuracy: 0.8507\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3303 - accuracy: 0.8757 - val_loss: 0.3183 - val_accuracy: 0.8408\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3241 - accuracy: 0.8664 - val_loss: 0.3067 - val_accuracy: 0.8507\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3045 - accuracy: 0.8747 - val_loss: 0.3184 - val_accuracy: 0.8657\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2531 - accuracy: 0.8918 - val_loss: 0.3128 - val_accuracy: 0.8607\n",
            "Score for fold 2: loss of 0.31275278329849243; accuracy of 86.06964945793152%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_48 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_49 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.6828 - accuracy: 0.5654 - val_loss: 0.5771 - val_accuracy: 0.7150\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6153 - accuracy: 0.6758 - val_loss: 0.5465 - val_accuracy: 0.6950\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5367 - accuracy: 0.7247 - val_loss: 0.5151 - val_accuracy: 0.7000\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5311 - accuracy: 0.7272 - val_loss: 0.4542 - val_accuracy: 0.7800\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4754 - accuracy: 0.7687 - val_loss: 0.5344 - val_accuracy: 0.7300\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.5168 - accuracy: 0.7340 - val_loss: 0.4727 - val_accuracy: 0.7950\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.4552 - accuracy: 0.8000 - val_loss: 0.4289 - val_accuracy: 0.7750\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4756 - accuracy: 0.7668 - val_loss: 0.4924 - val_accuracy: 0.8100\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5174 - accuracy: 0.8039 - val_loss: 0.4499 - val_accuracy: 0.7600\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4028 - accuracy: 0.8108 - val_loss: 0.4391 - val_accuracy: 0.8150\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4702 - accuracy: 0.7588 - val_loss: 0.4279 - val_accuracy: 0.7900\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4163 - accuracy: 0.8117 - val_loss: 0.3962 - val_accuracy: 0.8050\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4112 - accuracy: 0.8234 - val_loss: 0.4211 - val_accuracy: 0.8200\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4581 - accuracy: 0.7748 - val_loss: 0.4176 - val_accuracy: 0.8000\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4109 - accuracy: 0.8088 - val_loss: 0.4171 - val_accuracy: 0.7900\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4140 - accuracy: 0.8124 - val_loss: 0.4182 - val_accuracy: 0.8000\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4188 - accuracy: 0.7918 - val_loss: 0.4317 - val_accuracy: 0.8150\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3839 - accuracy: 0.8246 - val_loss: 0.4187 - val_accuracy: 0.7900\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3907 - accuracy: 0.8027 - val_loss: 0.4169 - val_accuracy: 0.8000\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3499 - accuracy: 0.8494 - val_loss: 0.3897 - val_accuracy: 0.7750\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3996 - accuracy: 0.8477 - val_loss: 0.3935 - val_accuracy: 0.8350\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3736 - accuracy: 0.8208 - val_loss: 0.4421 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4343 - accuracy: 0.7895 - val_loss: 0.4387 - val_accuracy: 0.7700\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3560 - accuracy: 0.8477 - val_loss: 0.3851 - val_accuracy: 0.7900\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3221 - accuracy: 0.8524 - val_loss: 0.3752 - val_accuracy: 0.8050\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3708 - accuracy: 0.8318 - val_loss: 0.3800 - val_accuracy: 0.8150\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3320 - accuracy: 0.8311 - val_loss: 0.3785 - val_accuracy: 0.8350\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3607 - accuracy: 0.8385 - val_loss: 0.3865 - val_accuracy: 0.8000\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3322 - accuracy: 0.8408 - val_loss: 0.4218 - val_accuracy: 0.8150\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3576 - accuracy: 0.8372 - val_loss: 0.4600 - val_accuracy: 0.8250\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2987 - accuracy: 0.8617 - val_loss: 0.4470 - val_accuracy: 0.7900\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2821 - accuracy: 0.8804 - val_loss: 0.4240 - val_accuracy: 0.7850\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3874 - accuracy: 0.8133 - val_loss: 0.4945 - val_accuracy: 0.8400\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4245 - accuracy: 0.8202 - val_loss: 0.4146 - val_accuracy: 0.8050\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3190 - accuracy: 0.8734 - val_loss: 0.4315 - val_accuracy: 0.8300\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3255 - accuracy: 0.8609 - val_loss: 0.3657 - val_accuracy: 0.8050\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3492 - accuracy: 0.8283 - val_loss: 0.3590 - val_accuracy: 0.8200\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3206 - accuracy: 0.8585 - val_loss: 0.3423 - val_accuracy: 0.8150\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3465 - accuracy: 0.8382 - val_loss: 0.3209 - val_accuracy: 0.8600\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2780 - accuracy: 0.8782 - val_loss: 0.3761 - val_accuracy: 0.8550\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2628 - accuracy: 0.8877 - val_loss: 0.3651 - val_accuracy: 0.8400\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3257 - accuracy: 0.8632 - val_loss: 0.4755 - val_accuracy: 0.8500\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3297 - accuracy: 0.8413 - val_loss: 0.4398 - val_accuracy: 0.8250\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3102 - accuracy: 0.8712 - val_loss: 0.4295 - val_accuracy: 0.8200\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3134 - accuracy: 0.8658 - val_loss: 0.4266 - val_accuracy: 0.8350\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3067 - accuracy: 0.8654 - val_loss: 0.4672 - val_accuracy: 0.8300\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3129 - accuracy: 0.8466 - val_loss: 0.4069 - val_accuracy: 0.8500\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3048 - accuracy: 0.8580 - val_loss: 0.4607 - val_accuracy: 0.8450\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2743 - accuracy: 0.8757 - val_loss: 0.3803 - val_accuracy: 0.8650\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3165 - accuracy: 0.8606 - val_loss: 0.3655 - val_accuracy: 0.8400\n",
            "Score for fold 3: loss of 0.36552727222442627; accuracy of 83.99999737739563%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_52 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_67 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.6734 - accuracy: 0.5795 - val_loss: 0.6129 - val_accuracy: 0.6700\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6030 - accuracy: 0.7049 - val_loss: 0.6341 - val_accuracy: 0.6800\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5660 - accuracy: 0.6977 - val_loss: 0.5257 - val_accuracy: 0.7000\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5313 - accuracy: 0.7112 - val_loss: 0.5612 - val_accuracy: 0.7000\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5551 - accuracy: 0.7301 - val_loss: 0.4967 - val_accuracy: 0.7350\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4693 - accuracy: 0.7927 - val_loss: 0.4902 - val_accuracy: 0.7750\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4803 - accuracy: 0.7674 - val_loss: 0.4770 - val_accuracy: 0.7550\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4733 - accuracy: 0.7842 - val_loss: 0.4899 - val_accuracy: 0.7550\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4506 - accuracy: 0.7753 - val_loss: 0.4592 - val_accuracy: 0.7500\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4713 - accuracy: 0.8178 - val_loss: 0.4364 - val_accuracy: 0.7850\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4472 - accuracy: 0.7846 - val_loss: 0.4438 - val_accuracy: 0.7650\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3964 - accuracy: 0.8286 - val_loss: 0.4250 - val_accuracy: 0.7750\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4329 - accuracy: 0.7961 - val_loss: 0.4310 - val_accuracy: 0.7850\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4242 - accuracy: 0.7989 - val_loss: 0.3949 - val_accuracy: 0.7850\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3860 - accuracy: 0.8243 - val_loss: 0.4034 - val_accuracy: 0.7850\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3970 - accuracy: 0.8363 - val_loss: 0.3915 - val_accuracy: 0.8000\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4055 - accuracy: 0.8086 - val_loss: 0.4231 - val_accuracy: 0.8050\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.4021 - accuracy: 0.8043 - val_loss: 0.4165 - val_accuracy: 0.7750\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4266 - accuracy: 0.8221 - val_loss: 0.4205 - val_accuracy: 0.7850\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4000 - accuracy: 0.8044 - val_loss: 0.4015 - val_accuracy: 0.8000\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3606 - accuracy: 0.8283 - val_loss: 0.3701 - val_accuracy: 0.8150\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3907 - accuracy: 0.8169 - val_loss: 0.5390 - val_accuracy: 0.7450\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4282 - accuracy: 0.7770 - val_loss: 0.3702 - val_accuracy: 0.7850\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3467 - accuracy: 0.8557 - val_loss: 0.3917 - val_accuracy: 0.7800\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3845 - accuracy: 0.8365 - val_loss: 0.4033 - val_accuracy: 0.7900\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3455 - accuracy: 0.8353 - val_loss: 0.4312 - val_accuracy: 0.8050\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3045 - accuracy: 0.8742 - val_loss: 0.3811 - val_accuracy: 0.7800\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3348 - accuracy: 0.8489 - val_loss: 0.3867 - val_accuracy: 0.8150\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3564 - accuracy: 0.8468 - val_loss: 0.3534 - val_accuracy: 0.8100\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2991 - accuracy: 0.8719 - val_loss: 0.3679 - val_accuracy: 0.8100\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3763 - accuracy: 0.8353 - val_loss: 0.3573 - val_accuracy: 0.8250\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3235 - accuracy: 0.8575 - val_loss: 0.3921 - val_accuracy: 0.8050\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3321 - accuracy: 0.8563 - val_loss: 0.3197 - val_accuracy: 0.8300\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2967 - accuracy: 0.8691 - val_loss: 0.3824 - val_accuracy: 0.8100\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3453 - accuracy: 0.8377 - val_loss: 0.3440 - val_accuracy: 0.8250\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3478 - accuracy: 0.8528 - val_loss: 0.3657 - val_accuracy: 0.8150\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3389 - accuracy: 0.8366 - val_loss: 0.3677 - val_accuracy: 0.8250\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3631 - accuracy: 0.8535 - val_loss: 0.3831 - val_accuracy: 0.8350\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3208 - accuracy: 0.8646 - val_loss: 0.3336 - val_accuracy: 0.8300\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2780 - accuracy: 0.8894 - val_loss: 0.3297 - val_accuracy: 0.8500\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3713 - accuracy: 0.8410 - val_loss: 0.3114 - val_accuracy: 0.8400\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2977 - accuracy: 0.8750 - val_loss: 0.4187 - val_accuracy: 0.8100\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3631 - accuracy: 0.8677 - val_loss: 0.3029 - val_accuracy: 0.8600\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2889 - accuracy: 0.8951 - val_loss: 0.3326 - val_accuracy: 0.8300\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2932 - accuracy: 0.8748 - val_loss: 0.3047 - val_accuracy: 0.8550\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3002 - accuracy: 0.8969 - val_loss: 0.3536 - val_accuracy: 0.8400\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3229 - accuracy: 0.8551 - val_loss: 0.2949 - val_accuracy: 0.8500\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2726 - accuracy: 0.9042 - val_loss: 0.3533 - val_accuracy: 0.8500\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2928 - accuracy: 0.8776 - val_loss: 0.2933 - val_accuracy: 0.8500\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2608 - accuracy: 0.8997 - val_loss: 0.3865 - val_accuracy: 0.8450\n",
            "Score for fold 4: loss of 0.3865421712398529; accuracy of 84.50000286102295%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_56 (Conv2D)           (None, 6, 1, 32)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 3, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 3, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (None, 2, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 2, 1, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_59 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 520,450\n",
            "Trainable params: 520,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.6962 - accuracy: 0.5988 - val_loss: 0.5994 - val_accuracy: 0.6800\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.6436 - accuracy: 0.6539 - val_loss: 0.5868 - val_accuracy: 0.6900\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.5630 - accuracy: 0.7242 - val_loss: 0.5244 - val_accuracy: 0.7350\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5456 - accuracy: 0.7250 - val_loss: 0.4785 - val_accuracy: 0.7550\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5177 - accuracy: 0.7463 - val_loss: 0.5382 - val_accuracy: 0.7100\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.5751 - accuracy: 0.7294 - val_loss: 0.4508 - val_accuracy: 0.7750\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4780 - accuracy: 0.7538 - val_loss: 0.4095 - val_accuracy: 0.7900\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4605 - accuracy: 0.7793 - val_loss: 0.4494 - val_accuracy: 0.7750\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4603 - accuracy: 0.7999 - val_loss: 0.4124 - val_accuracy: 0.7950\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.5024 - accuracy: 0.7502 - val_loss: 0.4090 - val_accuracy: 0.8050\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.4582 - accuracy: 0.7725 - val_loss: 0.4023 - val_accuracy: 0.8000\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4373 - accuracy: 0.8028 - val_loss: 0.4214 - val_accuracy: 0.7850\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.4595 - accuracy: 0.7657 - val_loss: 0.4151 - val_accuracy: 0.7700\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3987 - accuracy: 0.8290 - val_loss: 0.4261 - val_accuracy: 0.7900\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4355 - accuracy: 0.8020 - val_loss: 0.4018 - val_accuracy: 0.8050\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4759 - accuracy: 0.7906 - val_loss: 0.4073 - val_accuracy: 0.7750\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.4119 - accuracy: 0.8281 - val_loss: 0.4106 - val_accuracy: 0.8100\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4196 - accuracy: 0.8213 - val_loss: 0.3822 - val_accuracy: 0.8150\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.4238 - accuracy: 0.8201 - val_loss: 0.4117 - val_accuracy: 0.8150\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3891 - accuracy: 0.8145 - val_loss: 0.3625 - val_accuracy: 0.8200\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3695 - accuracy: 0.8223 - val_loss: 0.3531 - val_accuracy: 0.8150\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3818 - accuracy: 0.8246 - val_loss: 0.3725 - val_accuracy: 0.8400\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3697 - accuracy: 0.8301 - val_loss: 0.3632 - val_accuracy: 0.8450\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3293 - accuracy: 0.8539 - val_loss: 0.3779 - val_accuracy: 0.8350\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.4070 - accuracy: 0.8064 - val_loss: 0.3716 - val_accuracy: 0.8450\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3637 - accuracy: 0.8213 - val_loss: 0.4092 - val_accuracy: 0.8000\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3347 - accuracy: 0.8522 - val_loss: 0.4055 - val_accuracy: 0.7950\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3787 - accuracy: 0.8287 - val_loss: 0.3501 - val_accuracy: 0.8450\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3505 - accuracy: 0.8456 - val_loss: 0.3540 - val_accuracy: 0.8250\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3562 - accuracy: 0.8442 - val_loss: 0.3222 - val_accuracy: 0.8550\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3229 - accuracy: 0.8651 - val_loss: 0.3224 - val_accuracy: 0.8450\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3053 - accuracy: 0.8610 - val_loss: 0.3489 - val_accuracy: 0.8450\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3206 - accuracy: 0.8615 - val_loss: 0.3183 - val_accuracy: 0.8750\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3481 - accuracy: 0.8649 - val_loss: 0.3169 - val_accuracy: 0.8550\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3107 - accuracy: 0.8614 - val_loss: 0.3598 - val_accuracy: 0.8650\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3089 - accuracy: 0.8490 - val_loss: 0.3183 - val_accuracy: 0.8600\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3099 - accuracy: 0.8531 - val_loss: 0.3492 - val_accuracy: 0.8700\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.2876 - accuracy: 0.8768 - val_loss: 0.3446 - val_accuracy: 0.8700\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3154 - accuracy: 0.8558 - val_loss: 0.3228 - val_accuracy: 0.8750\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3028 - accuracy: 0.8570 - val_loss: 0.3400 - val_accuracy: 0.8600\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3101 - accuracy: 0.8619 - val_loss: 0.3250 - val_accuracy: 0.8850\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2711 - accuracy: 0.9034 - val_loss: 0.3107 - val_accuracy: 0.8950\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2676 - accuracy: 0.9079 - val_loss: 0.3495 - val_accuracy: 0.8400\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2923 - accuracy: 0.8543 - val_loss: 0.3037 - val_accuracy: 0.8450\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3024 - accuracy: 0.8637 - val_loss: 0.3857 - val_accuracy: 0.8650\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3190 - accuracy: 0.8629 - val_loss: 0.3239 - val_accuracy: 0.8600\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2954 - accuracy: 0.8625 - val_loss: 0.3299 - val_accuracy: 0.8650\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.2677 - accuracy: 0.8873 - val_loss: 0.3330 - val_accuracy: 0.8850\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 2s 8ms/step - loss: 0.3150 - accuracy: 0.8603 - val_loss: 0.3858 - val_accuracy: 0.8900\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.3404 - accuracy: 0.8771 - val_loss: 0.3939 - val_accuracy: 0.8050\n",
            "Score for fold 5: loss of 0.39389485120773315; accuracy of 80.50000071525574%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.3400593400001526 - Accuracy: 87.06467747688293%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.31275278329849243 - Accuracy: 86.06964945793152%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.36552727222442627 - Accuracy: 83.99999737739563%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.3865421712398529 - Accuracy: 84.50000286102295%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.39389485120773315 - Accuracy: 80.50000071525574%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 84.42686557769775 (+- 2.247871155700965)\n",
            "> Loss: 0.35975528359413145\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp0kwxfP3JMD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "outputId": "86edb498-9a21-4095-b9b2-25b53cb78b10"
      },
      "source": [
        "#Creating a grouped bar plot\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "speci = (list(speci))\n",
        "sensi =  (list(sensi))\n",
        "_f1score = (list(_f1score))\n",
        "_accuracy =(list(_accuracy))\n",
        "au = (list(au))\n",
        "barWidth = 0.25\n",
        "labels = ['Specificity', 'Sensitivity', 'AUC', 'F1-score', 'Accuracy']\n",
        "cnn_means = [speci[0], sensi[0], au[0], _f1score[0], _accuracy[0]]\n",
        "cnn1_means = [speci[1], sensi[1], au[1], _f1score[1], _accuracy[1]]\n",
        "cnn2_means = [speci[2], sensi[2], au[2], _f1score[2], _accuracy[2]]\n",
        "\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "# Set position of bar on X axis\n",
        "r1 = x\n",
        "r2 = [p + barWidth for p in r1]\n",
        "r3 = [p + barWidth for p in r2]\n",
        "fig, ax = plt.subplots(figsize=(12,10))\n",
        "rects1 = ax.bar(r1, (cnn_means), width, label='XY')\n",
        "rects2 = ax.bar(r2, (cnn1_means), width, label='XZ')\n",
        "rects3 = ax.bar(r3, (cnn2_means), width, label='YZ')\n",
        "\n",
        "\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Performance Scores', fontweight='bold', fontsize = 18)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels, fontweight='bold', fontsize = 16, horizontalalignment = 'left')\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{:.0%}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAghSQhSNhdm"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}